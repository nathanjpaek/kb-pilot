//
// Generated by LLVM NVPTX Back-End
//

.version 8.4
.target sm_90a
.address_size 64

	// .globl	_softmax_kernel
.extern .shared .align 16 .b8 global_smem[];

.visible .entry _softmax_kernel(
	.param .u64 _softmax_kernel_param_0,
	.param .u64 _softmax_kernel_param_1,
	.param .u32 _softmax_kernel_param_2
)
.maxntid 128, 1, 1
{
	.reg .pred 	%p<40>;
	.reg .b32 	%r<152>;
	.reg .f32 	%f<95>;
	.reg .b64 	%rd<27>;
	.loc	1 8 0
$L__func_begin0:
	.loc	1 8 0

	ld.param.u32 	%r13, [_softmax_kernel_param_2];
$L__tmp0:
	.loc	1 29 16
	setp.lt.s32 	%p2, %r13, 1;
	@%p2 bra 	$L__BB0_7;
	.loc	1 0 16
	ld.param.u64 	%rd4, [_softmax_kernel_param_0];
	ld.param.u64 	%rd5, [_softmax_kernel_param_1];
	// begin inline asm
	mov.u32 %r14, %ctaid.x;
	// end inline asm
	mul.lo.s32 	%r15, %r14, %r13;
	mul.wide.s32 	%rd6, %r15, 4;
	add.s64 	%rd1, %rd4, %rd6;
	add.s64 	%rd2, %rd5, %rd6;
	mov.u32 	%r1, %tid.x;
	and.b32  	%r2, %r1, 31;
	shr.u32 	%r3, %r1, 5;
	shl.b32 	%r16, %r1, 2;
	and.b32  	%r4, %r16, 508;
	cvt.u64.u32 	%rd3, %r4;
	and.b32  	%r18, %r3, 3;
	shl.b32 	%r19, %r18, 2;
	mov.u32 	%r20, global_smem;
	add.s32 	%r5, %r20, %r19;
	setp.lt.s32 	%p3, %r1, 4;
	add.s32 	%r42, %r20, %r16;
	and.b32  	%r22, %r1, 3;
	setp.eq.s32 	%p4, %r22, 0;
	and.pred  	%p17, %p3, %p4;
	mov.f32 	%f93, 0fFF800000;
	mov.b32 	%r149, 0;
	setp.eq.s32 	%p15, %r2, 0;
	shl.b64 	%rd11, %rd3, 2;
$L__BB0_2:
	.loc	1 30 22
	add.s32 	%r45, %r4, %r149;
	.loc	1 30 30
	add.s32 	%r46, %r45, 512;
	setp.lt.s32 	%p5, %r45, %r13;
	setp.lt.s32 	%p10, %r46, %r13;
	.loc	1 31 32
	mul.wide.s32 	%rd9, %r149, 4;
	add.s64 	%rd10, %rd1, %rd9;
	.loc	1 31 38
	add.s64 	%rd7, %rd10, %rd11;
	add.s64 	%rd8, %rd7, 2048;
	mov.b32 	%r38, -8388608;
	.loc	1 31 20
	// begin inline asm
	mov.u32 %r23, 0x0;
	mov.u32 %r24, 0x0;
	mov.u32 %r25, 0x0;
	mov.u32 %r26, 0x0;
	@%p5 ld.global.v4.b32 { %r23, %r24, %r25, %r26 }, [ %rd7 + 0 ];
	@!%p5 mov.u32 %r23, %r38;
	@!%p5 mov.u32 %r24, %r38;
	@!%p5 mov.u32 %r25, %r38;
	@!%p5 mov.u32 %r26, %r38;
	// end inline asm
	mov.b32 	%f6, %r23;
	mov.b32 	%f7, %r24;
	mov.b32 	%f8, %r25;
	mov.b32 	%f9, %r26;
	// begin inline asm
	mov.u32 %r31, 0x0;
	mov.u32 %r32, 0x0;
	mov.u32 %r33, 0x0;
	mov.u32 %r34, 0x0;
	@%p10 ld.global.v4.b32 { %r31, %r32, %r33, %r34 }, [ %rd8 + 0 ];
	@!%p10 mov.u32 %r31, %r38;
	@!%p10 mov.u32 %r32, %r38;
	@!%p10 mov.u32 %r33, %r38;
	@!%p10 mov.u32 %r34, %r38;
	// end inline asm
	mov.b32 	%f10, %r31;
	mov.b32 	%f11, %r32;
	mov.b32 	%f12, %r33;
	mov.b32 	%f13, %r34;
$L__tmp1:
	.loc	2 184 40
	bar.sync 	0;
	.loc	2 163 27
	max.f32 	%f14, %f6, %f7;
	max.f32 	%f15, %f14, %f8;
	max.f32 	%f16, %f15, %f9;
	max.f32 	%f17, %f16, %f10;
	max.f32 	%f18, %f17, %f11;
	max.f32 	%f19, %f18, %f12;
	max.f32 	%f20, %f19, %f13;
	.loc	2 184 40
	mov.b32 	%r47, %f20;
	shfl.sync.bfly.b32	%r48, %r47, 16, 31, -1;
	mov.b32 	%f21, %r48;
	.loc	2 163 27
	max.f32 	%f22, %f20, %f21;
	.loc	2 184 40
	mov.b32 	%r49, %f22;
	shfl.sync.bfly.b32	%r50, %r49, 8, 31, -1;
	mov.b32 	%f23, %r50;
	.loc	2 163 27
	max.f32 	%f24, %f22, %f23;
	.loc	2 184 40
	mov.b32 	%r51, %f24;
	shfl.sync.bfly.b32	%r52, %r51, 4, 31, -1;
	mov.b32 	%f25, %r52;
	.loc	2 163 27
	max.f32 	%f26, %f24, %f25;
	.loc	2 184 40
	mov.b32 	%r53, %f26;
	shfl.sync.bfly.b32	%r54, %r53, 2, 31, -1;
	mov.b32 	%f27, %r54;
	.loc	2 163 27
	max.f32 	%f28, %f26, %f27;
	.loc	2 184 40
	mov.b32 	%r55, %f28;
	shfl.sync.bfly.b32	%r56, %r55, 1, 31, -1;
	mov.b32 	%f29, %r56;
	.loc	2 163 27
	max.f32 	%f30, %f28, %f29;
	.loc	2 184 40
	mov.b32 	%r40, %f30;
	// begin inline asm
	@%p15 st.shared.b32 [ %r5 + 0 ], %r40;
	// end inline asm
	bar.sync 	0;
	// begin inline asm
	@%p3 ld.shared.b32 %r41, [ %r42 + 0 ];
	// end inline asm
	mov.b32 	%f31, %r41;
	shfl.sync.bfly.b32	%r57, %r41, 2, 31, -1;
	mov.b32 	%f32, %r57;
	.loc	2 163 27
	max.f32 	%f33, %f31, %f32;
	.loc	2 184 40
	mov.b32 	%r58, %f33;
	shfl.sync.bfly.b32	%r59, %r58, 1, 31, -1;
	mov.b32 	%f34, %r59;
	.loc	2 163 27
	max.f32 	%f35, %f33, %f34;
	.loc	2 184 40
	mov.b32 	%r44, %f35;
	// begin inline asm
	@%p17 st.shared.b32 [ %r42 + 0 ], %r44;
	// end inline asm
	bar.sync 	0;
	ld.shared.f32 	%f36, [global_smem];
$L__tmp2:
	.loc	1 33 38
	max.f32 	%f93, %f93, %f36;
	.loc	1 34 15
	add.s32 	%r149, %r149, 1024;
	.loc	1 29 16
	setp.lt.s32 	%p18, %r149, %r13;
	@%p18 bra 	$L__BB0_2;
	.loc	1 0 16
	mov.f32 	%f94, 0f00000000;
	mov.b32 	%r150, 0;
$L__BB0_4:
	.loc	1 40 22
	add.s32 	%r91, %r4, %r150;
	.loc	1 40 30
	add.s32 	%r92, %r91, 512;
	setp.lt.s32 	%p19, %r91, %r13;
	setp.lt.s32 	%p24, %r92, %r13;
	.loc	1 41 32
	mul.wide.s32 	%rd16, %r150, 4;
	add.s64 	%rd17, %rd1, %rd16;
	.loc	1 41 38
	add.s64 	%rd12, %rd17, %rd11;
	add.s64 	%rd13, %rd12, 2048;
	.loc	1 41 20
	// begin inline asm
	mov.u32 %r61, 0x0;
	mov.u32 %r62, 0x0;
	mov.u32 %r63, 0x0;
	mov.u32 %r64, 0x0;
	@%p19 ld.global.v4.b32 { %r61, %r62, %r63, %r64 }, [ %rd12 + 0 ];
	@!%p19 mov.u32 %r61, %r38;
	@!%p19 mov.u32 %r62, %r38;
	@!%p19 mov.u32 %r63, %r38;
	@!%p19 mov.u32 %r64, %r38;
	// end inline asm
	mov.b32 	%f54, %r61;
	mov.b32 	%f55, %r62;
	mov.b32 	%f56, %r63;
	mov.b32 	%f57, %r64;
	// begin inline asm
	mov.u32 %r69, 0x0;
	mov.u32 %r70, 0x0;
	mov.u32 %r71, 0x0;
	mov.u32 %r72, 0x0;
	@%p24 ld.global.v4.b32 { %r69, %r70, %r71, %r72 }, [ %rd13 + 0 ];
	@!%p24 mov.u32 %r69, %r38;
	@!%p24 mov.u32 %r70, %r38;
	@!%p24 mov.u32 %r71, %r38;
	@!%p24 mov.u32 %r72, %r38;
	// end inline asm
	mov.b32 	%f58, %r69;
	mov.b32 	%f59, %r70;
	mov.b32 	%f60, %r71;
	mov.b32 	%f61, %r72;
	.loc	1 42 27
	sub.f32 	%f62, %f54, %f93;
	sub.f32 	%f63, %f55, %f93;
	sub.f32 	%f64, %f56, %f93;
	sub.f32 	%f65, %f57, %f93;
	sub.f32 	%f66, %f58, %f93;
	sub.f32 	%f67, %f59, %f93;
	sub.f32 	%f68, %f60, %f93;
	sub.f32 	%f69, %f61, %f93;
	.loc	1 42 23
	mul.f32 	%f39, %f62, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f38, %f39;
	// end inline asm
	mul.f32 	%f41, %f63, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f40, %f41;
	// end inline asm
	mul.f32 	%f43, %f64, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f42, %f43;
	// end inline asm
	mul.f32 	%f45, %f65, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f44, %f45;
	// end inline asm
	mul.f32 	%f47, %f66, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f46, %f47;
	// end inline asm
	mul.f32 	%f49, %f67, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f48, %f49;
	// end inline asm
	mul.f32 	%f51, %f68, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f50, %f51;
	// end inline asm
	mul.f32 	%f53, %f69, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f52, %f53;
	// end inline asm
	.loc	1 43 29
	add.s64 	%rd19, %rd2, %rd16;
	.loc	1 43 35
	add.s64 	%rd14, %rd19, %rd11;
	add.s64 	%rd15, %rd14, 2048;
	.loc	1 43 41
	mov.b32 	%r77, %f38;
	mov.b32 	%r78, %f40;
	mov.b32 	%r79, %f42;
	mov.b32 	%r80, %f44;
	// begin inline asm
	@%p19 st.global.v4.b32 [ %rd14 + 0 ], { %r77, %r78, %r79, %r80 };
	// end inline asm
	mov.b32 	%r81, %f46;
	mov.b32 	%r82, %f48;
	mov.b32 	%r83, %f50;
	mov.b32 	%r84, %f52;
	// begin inline asm
	@%p24 st.global.v4.b32 [ %rd15 + 0 ], { %r81, %r82, %r83, %r84 };
	// end inline asm
$L__tmp3:
	.loc	2 267 36
	bar.sync 	0;
	.loc	2 256 15
	add.f32 	%f70, %f38, %f40;
	add.f32 	%f71, %f70, %f42;
	add.f32 	%f72, %f71, %f44;
	add.f32 	%f73, %f72, %f46;
	add.f32 	%f74, %f73, %f48;
	add.f32 	%f75, %f74, %f50;
	add.f32 	%f76, %f75, %f52;
	.loc	2 267 36
	mov.b32 	%r93, %f76;
	shfl.sync.bfly.b32	%r94, %r93, 16, 31, -1;
	mov.b32 	%f77, %r94;
	.loc	2 256 15
	add.f32 	%f78, %f76, %f77;
	.loc	2 267 36
	mov.b32 	%r95, %f78;
	shfl.sync.bfly.b32	%r96, %r95, 8, 31, -1;
	mov.b32 	%f79, %r96;
	.loc	2 256 15
	add.f32 	%f80, %f78, %f79;
	.loc	2 267 36
	mov.b32 	%r97, %f80;
	shfl.sync.bfly.b32	%r98, %r97, 4, 31, -1;
	mov.b32 	%f81, %r98;
	.loc	2 256 15
	add.f32 	%f82, %f80, %f81;
	.loc	2 267 36
	mov.b32 	%r99, %f82;
	shfl.sync.bfly.b32	%r100, %r99, 2, 31, -1;
	mov.b32 	%f83, %r100;
	.loc	2 256 15
	add.f32 	%f84, %f82, %f83;
	.loc	2 267 36
	mov.b32 	%r101, %f84;
	shfl.sync.bfly.b32	%r102, %r101, 1, 31, -1;
	mov.b32 	%f85, %r102;
	.loc	2 256 15
	add.f32 	%f86, %f84, %f85;
	.loc	2 267 36
	mov.b32 	%r86, %f86;
	// begin inline asm
	@%p15 st.shared.b32 [ %r5 + 0 ], %r86;
	// end inline asm
	bar.sync 	0;
	// begin inline asm
	@%p3 ld.shared.b32 %r87, [ %r42 + 0 ];
	// end inline asm
	mov.b32 	%f87, %r87;
	shfl.sync.bfly.b32	%r103, %r87, 2, 31, -1;
	mov.b32 	%f88, %r103;
	.loc	2 256 15
	add.f32 	%f89, %f87, %f88;
	.loc	2 267 36
	mov.b32 	%r104, %f89;
	shfl.sync.bfly.b32	%r105, %r104, 1, 31, -1;
	mov.b32 	%f90, %r105;
	.loc	2 256 15
	add.f32 	%f91, %f89, %f90;
	.loc	2 267 36
	mov.b32 	%r90, %f91;
	// begin inline asm
	@%p17 st.shared.b32 [ %r42 + 0 ], %r90;
	// end inline asm
	bar.sync 	0;
	ld.shared.f32 	%f92, [global_smem];
$L__tmp4:
	.loc	1 44 19
	add.f32 	%f94, %f94, %f92;
	.loc	1 45 15
	add.s32 	%r150, %r150, 1024;
	.loc	1 39 16
	setp.lt.s32 	%p34, %r150, %r13;
	@%p34 bra 	$L__BB0_4;
	.loc	1 0 16
	mov.b32 	%r151, 0;
$L__BB0_6:
	.loc	1 50 22
	add.s32 	%r147, %r4, %r151;
	.loc	1 50 30
	add.s32 	%r148, %r147, 512;
	setp.lt.s32 	%p35, %r147, %r13;
	setp.lt.s32 	%p36, %r148, %r13;
	.loc	1 51 32
	mul.wide.s32 	%rd24, %r151, 4;
	add.s64 	%rd25, %rd2, %rd24;
	.loc	1 51 38
	add.s64 	%rd20, %rd25, %rd11;
	add.s64 	%rd21, %rd20, 2048;
	.loc	1 51 20
	// begin inline asm
	mov.u32 %r107, 0x0;
	mov.u32 %r108, 0x0;
	mov.u32 %r109, 0x0;
	mov.u32 %r110, 0x0;
	@%p35 ld.global.v4.b32 { %r107, %r108, %r109, %r110 }, [ %rd20 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r111, 0x0;
	mov.u32 %r112, 0x0;
	mov.u32 %r113, 0x0;
	mov.u32 %r114, 0x0;
	@%p36 ld.global.v4.b32 { %r111, %r112, %r113, %r114 }, [ %rd21 + 0 ];
	// end inline asm
	.loc	1 52 45
	mov.b32 	%r117, %f94;
	// begin inline asm
	div.full.f32 %r115, %r107, %r117;
	// end inline asm
	// begin inline asm
	div.full.f32 %r118, %r108, %r117;
	// end inline asm
	// begin inline asm
	div.full.f32 %r121, %r109, %r117;
	// end inline asm
	// begin inline asm
	div.full.f32 %r124, %r110, %r117;
	// end inline asm
	// begin inline asm
	div.full.f32 %r127, %r111, %r117;
	// end inline asm
	// begin inline asm
	div.full.f32 %r130, %r112, %r117;
	// end inline asm
	// begin inline asm
	div.full.f32 %r133, %r113, %r117;
	// end inline asm
	// begin inline asm
	div.full.f32 %r136, %r114, %r117;
	// end inline asm
	.loc	1 52 41
	// begin inline asm
	@%p35 st.global.v4.b32 [ %rd20 + 0 ], { %r115, %r118, %r121, %r124 };
	// end inline asm
	// begin inline asm
	@%p36 st.global.v4.b32 [ %rd21 + 0 ], { %r127, %r130, %r133, %r136 };
	// end inline asm
	.loc	1 53 15
	add.s32 	%r151, %r151, 1024;
	.loc	1 49 16
	setp.lt.s32 	%p39, %r151, %r13;
	@%p39 bra 	$L__BB0_6;
$L__BB0_7:
	.loc	1 49 4
	ret;
$L__tmp5:
$L__func_end0:

}
	.file	1 "/tmp/tmpr9xf5gmw.py"
	.file	2 "/usr/local/lib/python3.10/site-packages/triton/language/standard.py"
	.section	.debug_abbrev
	{
.b8 1
.b8 17
.b8 1
.b8 37
.b8 8
.b8 19
.b8 5
.b8 3
.b8 8
.b8 16
.b8 6
.b8 27
.b8 8
.b8 17
.b8 1
.b8 18
.b8 1
.b8 0
.b8 0
.b8 2
.b8 46
.b8 0
.b8 3
.b8 8
.b8 32
.b8 11
.b8 0
.b8 0
.b8 3
.b8 46
.b8 1
.b8 17
.b8 1
.b8 18
.b8 1
.b8 49
.b8 19
.b8 0
.b8 0
.b8 4
.b8 29
.b8 0
.b8 49
.b8 19
.b8 17
.b8 1
.b8 18
.b8 1
.b8 88
.b8 11
.b8 89
.b8 11
.b8 87
.b8 11
.b8 0
.b8 0
.b8 0
	}
	.section	.debug_info
	{
.b32 146
.b8 2
.b8 0
.b32 .debug_abbrev
.b8 8
.b8 1
.b8 116
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2
.b8 0
.b8 116
.b8 109
.b8 112
.b8 114
.b8 57
.b8 120
.b8 102
.b8 53
.b8 103
.b8 109
.b8 119
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line
.b8 47
.b8 116
.b8 109
.b8 112
.b8 0
.b64 $L__func_begin0
.b64 $L__func_end0
.b8 2
.b8 95
.b8 115
.b8 111
.b8 102
.b8 116
.b8 109
.b8 97
.b8 120
.b8 95
.b8 107
.b8 101
.b8 114
.b8 110
.b8 101
.b8 108
.b8 0
.b8 1
.b8 3
.b64 $L__func_begin0
.b64 $L__func_end0
.b32 61
.b8 4
.b32 61
.b64 $L__tmp1
.b64 $L__tmp2
.b8 1
.b8 32
.b8 19
.b8 4
.b32 61
.b64 $L__tmp3
.b64 $L__tmp4
.b8 1
.b8 44
.b8 26
.b8 0
.b8 0
	}
	.section	.debug_loc	{	}
