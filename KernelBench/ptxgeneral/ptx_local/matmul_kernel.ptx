//
// Generated by LLVM NVPTX Back-End
//

.version 8.4
.target sm_90a
.address_size 64

	// .globl	matmul_kernel
.extern .shared .align 16 .b8 global_smem[];

.visible .entry matmul_kernel(
	.param .u64 matmul_kernel_param_0,
	.param .u64 matmul_kernel_param_1,
	.param .u64 matmul_kernel_param_2,
	.param .u32 matmul_kernel_param_3,
	.param .u32 matmul_kernel_param_4,
	.param .u32 matmul_kernel_param_5,
	.param .u32 matmul_kernel_param_6,
	.param .u32 matmul_kernel_param_7,
	.param .u32 matmul_kernel_param_8
)
.maxntid 128, 1, 1
{
	.reg .pred 	%p<171>;
	.reg .b32 	%r<574>;
	.reg .f32 	%f<1943>;
	.reg .b64 	%rd<165>;
	.loc	1 8 0
$L__func_begin0:
	.loc	1 8 0

	ld.param.u32 	%r60, [matmul_kernel_param_8];
	ld.param.u32 	%r58, [matmul_kernel_param_6];
	ld.param.u32 	%r57, [matmul_kernel_param_5];
	ld.param.u32 	%r56, [matmul_kernel_param_4];
	ld.param.u32 	%r55, [matmul_kernel_param_3];
	ld.param.u64 	%rd28, [matmul_kernel_param_2];
	ld.param.u64 	%rd163, [matmul_kernel_param_0];
$L__tmp0:
	.loc	1 22 24
	// begin inline asm
	mov.u32 %r61, %ctaid.x;
	// end inline asm
$L__tmp1:
	.loc	2 44 22
	add.s32 	%r94, %r56, 127;
	.loc	2 44 28
	shr.s32 	%r95, %r94, 31;
	shr.u32 	%r96, %r95, 25;
	add.s32 	%r97, %r94, %r96;
	shr.s32 	%r98, %r97, 7;
$L__tmp2:
	.loc	1 26 38
	shl.b32 	%r99, %r98, 3;
	.loc	1 26 23
	div.s32 	%r100, %r61, %r99;
	.loc	1 28 34
	div.s32 	%r102, %r61, %r98;
	.loc	1 28 47
	shr.s32 	%r103, %r102, 31;
	shr.u32 	%r104, %r103, 29;
	add.s32 	%r105, %r102, %r104;
	and.b32  	%r106, %r105, 33554424;
	sub.s32 	%r107, %r102, %r106;
	mul.lo.s32 	%r2, %r102, %r98;
	sub.s32 	%r108, %r61, %r2;
	.loc	1 34 21
	shl.b32 	%r109, %r100, 10;
	shl.b32 	%r110, %r107, 7;
	add.s32 	%r3, %r110, %r109;
	.loc	1 34 44
	mov.u32 	%r4, %tid.x;
	bfe.u32 	%r6, %r4, 3, 4;
	or.b32  	%r111, %r6, 16;
	or.b32  	%r112, %r6, 32;
	or.b32  	%r113, %r6, 48;
	or.b32  	%r114, %r6, 64;
	or.b32  	%r115, %r6, 80;
	or.b32  	%r116, %r6, 96;
	or.b32  	%r117, %r6, 112;
	bfe.u32 	%r7, %r4, 5, 2;
	or.b32  	%r8, %r7, 4;
	or.b32  	%r9, %r7, 8;
	or.b32  	%r10, %r7, 12;
	or.b32  	%r11, %r7, 16;
	or.b32  	%r12, %r7, 20;
	or.b32  	%r13, %r7, 24;
	or.b32  	%r14, %r7, 28;
	shl.b32 	%r118, %r4, 2;
	and.b32  	%r15, %r118, 28;
	and.b32  	%r16, %r118, 124;
	.loc	1 34 31
	or.b32  	%r119, %r3, %r6;
	or.b32  	%r120, %r3, %r111;
	or.b32  	%r121, %r3, %r112;
	or.b32  	%r122, %r3, %r113;
	or.b32  	%r123, %r3, %r114;
	or.b32  	%r124, %r3, %r115;
	or.b32  	%r125, %r3, %r116;
	or.b32  	%r126, %r3, %r117;
	.loc	1 35 21
	shl.b32 	%r127, %r108, 7;
	.loc	1 35 31
	or.b32  	%r17, %r127, %r16;
	.loc	1 39 52
	mad.lo.s32 	%r128, %r119, %r58, %r15;
	mad.lo.s32 	%r129, %r120, %r58, %r15;
	mad.lo.s32 	%r130, %r121, %r58, %r15;
	mad.lo.s32 	%r131, %r122, %r58, %r15;
	mad.lo.s32 	%r132, %r123, %r58, %r15;
	mad.lo.s32 	%r133, %r124, %r58, %r15;
	mad.lo.s32 	%r134, %r125, %r58, %r15;
	mad.lo.s32 	%r135, %r126, %r58, %r15;
	.loc	1 39 22
	mul.wide.s32 	%rd45, %r128, 4;
	add.s64 	%rd29, %rd163, %rd45;
	mul.wide.s32 	%rd46, %r129, 4;
	add.s64 	%rd30, %rd163, %rd46;
	mul.wide.s32 	%rd47, %r130, 4;
	add.s64 	%rd31, %rd163, %rd47;
	mul.wide.s32 	%rd48, %r131, 4;
	add.s64 	%rd32, %rd163, %rd48;
	mul.wide.s32 	%rd49, %r132, 4;
	add.s64 	%rd33, %rd163, %rd49;
	mul.wide.s32 	%rd50, %r133, 4;
	add.s64 	%rd34, %rd163, %rd50;
	mul.wide.s32 	%rd51, %r134, 4;
	add.s64 	%rd35, %rd163, %rd51;
	mul.wide.s32 	%rd52, %r135, 4;
	add.s64 	%rd36, %rd163, %rd52;
	.loc	1 51 36
	setp.lt.s32 	%p33, %r119, %r55;
	setp.lt.s32 	%p34, %r120, %r55;
	setp.lt.s32 	%p35, %r121, %r55;
	setp.lt.s32 	%p36, %r122, %r55;
	setp.lt.s32 	%p37, %r123, %r55;
	setp.lt.s32 	%p38, %r124, %r55;
	setp.lt.s32 	%p39, %r125, %r55;
	setp.lt.s32 	%p40, %r126, %r55;
	.loc	1 51 60
	setp.lt.s32 	%p41, %r15, %r57;
	.loc	1 51 42
	and.pred  	%p1, %p41, %p33;
	and.pred  	%p2, %p41, %p34;
	and.pred  	%p3, %p41, %p35;
	and.pred  	%p4, %p41, %p36;
	and.pred  	%p5, %p41, %p37;
	and.pred  	%p6, %p41, %p38;
	and.pred  	%p7, %p41, %p39;
	and.pred  	%p8, %p41, %p40;
	.loc	1 56 60
	setp.lt.s32 	%p50, %r17, %r56;
	.loc	1 48 25
	setp.lt.s32 	%p51, %r57, 1;
	setp.gt.s32 	%p52, %r57, 0;
	.loc	1 50 12
	shl.b32 	%r136, %r6, 5;
	shr.u32 	%r137, %r4, 1;
	xor.b32  	%r138, %r118, %r137;
	and.b32  	%r139, %r138, 28;
	or.b32  	%r18, %r136, %r139;
	shl.b32 	%r140, %r18, 2;
	mov.u32 	%r141, global_smem;
	add.s32 	%r62, %r141, %r140;
	shl.b32 	%r142, %r111, 5;
	or.b32  	%r19, %r142, %r139;
	shl.b32 	%r143, %r19, 2;
	add.s32 	%r64, %r141, %r143;
	shl.b32 	%r144, %r112, 5;
	or.b32  	%r20, %r144, %r139;
	shl.b32 	%r145, %r20, 2;
	add.s32 	%r66, %r141, %r145;
	shl.b32 	%r146, %r113, 5;
	or.b32  	%r21, %r146, %r139;
	shl.b32 	%r147, %r21, 2;
	add.s32 	%r68, %r141, %r147;
	shl.b32 	%r148, %r114, 5;
	or.b32  	%r22, %r148, %r139;
	shl.b32 	%r149, %r22, 2;
	add.s32 	%r70, %r141, %r149;
	shl.b32 	%r150, %r115, 5;
	or.b32  	%r23, %r150, %r139;
	shl.b32 	%r151, %r23, 2;
	add.s32 	%r72, %r141, %r151;
	shl.b32 	%r152, %r116, 5;
	or.b32  	%r24, %r152, %r139;
	shl.b32 	%r153, %r24, 2;
	add.s32 	%r74, %r141, %r153;
	shl.b32 	%r154, %r117, 5;
	or.b32  	%r25, %r154, %r139;
	shl.b32 	%r155, %r25, 2;
	add.s32 	%r76, %r141, %r155;
	selp.b32 	%r156, 16, 0, %p1;
	selp.b32 	%r63, %r156, 0, %p52;
	mov.pred 	%p17, -1;
	// begin inline asm
	@%p17 cp.async.cg.shared.global [ %r62 + 0 ], [ %rd29 + 0 ], 0x10, %r63;
	// end inline asm
	selp.b32 	%r157, 16, 0, %p2;
	selp.b32 	%r65, %r157, 0, %p52;
	// begin inline asm
	@%p17 cp.async.cg.shared.global [ %r64 + 0 ], [ %rd30 + 0 ], 0x10, %r65;
	// end inline asm
	selp.b32 	%r158, 16, 0, %p3;
	selp.b32 	%r67, %r158, 0, %p52;
	// begin inline asm
	@%p17 cp.async.cg.shared.global [ %r66 + 0 ], [ %rd31 + 0 ], 0x10, %r67;
	// end inline asm
	selp.b32 	%r159, 16, 0, %p4;
	selp.b32 	%r69, %r159, 0, %p52;
	// begin inline asm
	@%p17 cp.async.cg.shared.global [ %r68 + 0 ], [ %rd32 + 0 ], 0x10, %r69;
	// end inline asm
	selp.b32 	%r160, 16, 0, %p5;
	selp.b32 	%r71, %r160, 0, %p52;
	// begin inline asm
	@%p17 cp.async.cg.shared.global [ %r70 + 0 ], [ %rd33 + 0 ], 0x10, %r71;
	// end inline asm
	selp.b32 	%r161, 16, 0, %p6;
	selp.b32 	%r73, %r161, 0, %p52;
	// begin inline asm
	@%p17 cp.async.cg.shared.global [ %r72 + 0 ], [ %rd34 + 0 ], 0x10, %r73;
	// end inline asm
	selp.b32 	%r162, 16, 0, %p7;
	selp.b32 	%r75, %r162, 0, %p52;
	// begin inline asm
	@%p17 cp.async.cg.shared.global [ %r74 + 0 ], [ %rd35 + 0 ], 0x10, %r75;
	// end inline asm
	selp.b32 	%r163, 16, 0, %p8;
	selp.b32 	%r77, %r163, 0, %p52;
	// begin inline asm
	@%p17 cp.async.cg.shared.global [ %r76 + 0 ], [ %rd36 + 0 ], 0x10, %r77;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	.loc	1 48 25
	setp.gt.s32 	%p53, %r57, 32;
	.loc	1 60 18
	add.s64 	%rd37, %rd29, 128;
	add.s64 	%rd38, %rd30, 128;
	add.s64 	%rd39, %rd31, 128;
	add.s64 	%rd40, %rd32, 128;
	add.s64 	%rd41, %rd33, 128;
	add.s64 	%rd42, %rd34, 128;
	add.s64 	%rd43, %rd35, 128;
	add.s64 	%rd44, %rd36, 128;
	.loc	1 50 12
	bar.sync 	0;
	add.s32 	%r164, %r141, 16384;
	add.s32 	%r78, %r164, %r140;
	add.s32 	%r80, %r164, %r143;
	add.s32 	%r82, %r164, %r145;
	add.s32 	%r84, %r164, %r147;
	add.s32 	%r86, %r164, %r149;
	add.s32 	%r88, %r164, %r151;
	add.s32 	%r90, %r164, %r153;
	add.s32 	%r92, %r164, %r155;
	selp.b32 	%r79, %r156, 0, %p53;
	// begin inline asm
	@%p17 cp.async.cg.shared.global [ %r78 + 0 ], [ %rd37 + 0 ], 0x10, %r79;
	// end inline asm
	selp.b32 	%r81, %r157, 0, %p53;
	// begin inline asm
	@%p17 cp.async.cg.shared.global [ %r80 + 0 ], [ %rd38 + 0 ], 0x10, %r81;
	// end inline asm
	selp.b32 	%r83, %r158, 0, %p53;
	// begin inline asm
	@%p17 cp.async.cg.shared.global [ %r82 + 0 ], [ %rd39 + 0 ], 0x10, %r83;
	// end inline asm
	selp.b32 	%r85, %r159, 0, %p53;
	// begin inline asm
	@%p17 cp.async.cg.shared.global [ %r84 + 0 ], [ %rd40 + 0 ], 0x10, %r85;
	// end inline asm
	selp.b32 	%r87, %r160, 0, %p53;
	// begin inline asm
	@%p17 cp.async.cg.shared.global [ %r86 + 0 ], [ %rd41 + 0 ], 0x10, %r87;
	// end inline asm
	selp.b32 	%r89, %r161, 0, %p53;
	// begin inline asm
	@%p17 cp.async.cg.shared.global [ %r88 + 0 ], [ %rd42 + 0 ], 0x10, %r89;
	// end inline asm
	selp.b32 	%r91, %r162, 0, %p53;
	// begin inline asm
	@%p17 cp.async.cg.shared.global [ %r90 + 0 ], [ %rd43 + 0 ], 0x10, %r91;
	// end inline asm
	selp.b32 	%r93, %r163, 0, %p53;
	// begin inline asm
	@%p17 cp.async.cg.shared.global [ %r92 + 0 ], [ %rd44 + 0 ], 0x10, %r93;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	mov.f32 	%f1687, 0f00000000;
	mov.f32 	%f1688, %f1687;
	mov.f32 	%f1689, %f1687;
	mov.f32 	%f1690, %f1687;
	mov.f32 	%f1691, %f1687;
	mov.f32 	%f1692, %f1687;
	mov.f32 	%f1693, %f1687;
	mov.f32 	%f1694, %f1687;
	mov.f32 	%f1695, %f1687;
	mov.f32 	%f1696, %f1687;
	mov.f32 	%f1697, %f1687;
	mov.f32 	%f1698, %f1687;
	mov.f32 	%f1699, %f1687;
	mov.f32 	%f1700, %f1687;
	mov.f32 	%f1701, %f1687;
	mov.f32 	%f1702, %f1687;
	mov.f32 	%f1703, %f1687;
	mov.f32 	%f1704, %f1687;
	mov.f32 	%f1705, %f1687;
	mov.f32 	%f1706, %f1687;
	mov.f32 	%f1707, %f1687;
	mov.f32 	%f1708, %f1687;
	mov.f32 	%f1709, %f1687;
	mov.f32 	%f1710, %f1687;
	mov.f32 	%f1711, %f1687;
	mov.f32 	%f1712, %f1687;
	mov.f32 	%f1713, %f1687;
	mov.f32 	%f1714, %f1687;
	mov.f32 	%f1715, %f1687;
	mov.f32 	%f1716, %f1687;
	mov.f32 	%f1717, %f1687;
	mov.f32 	%f1718, %f1687;
	mov.f32 	%f1719, %f1687;
	mov.f32 	%f1720, %f1687;
	mov.f32 	%f1721, %f1687;
	mov.f32 	%f1722, %f1687;
	mov.f32 	%f1723, %f1687;
	mov.f32 	%f1724, %f1687;
	mov.f32 	%f1725, %f1687;
	mov.f32 	%f1726, %f1687;
	mov.f32 	%f1727, %f1687;
	mov.f32 	%f1728, %f1687;
	mov.f32 	%f1729, %f1687;
	mov.f32 	%f1730, %f1687;
	mov.f32 	%f1731, %f1687;
	mov.f32 	%f1732, %f1687;
	mov.f32 	%f1733, %f1687;
	mov.f32 	%f1734, %f1687;
	mov.f32 	%f1735, %f1687;
	mov.f32 	%f1736, %f1687;
	mov.f32 	%f1737, %f1687;
	mov.f32 	%f1738, %f1687;
	mov.f32 	%f1739, %f1687;
	mov.f32 	%f1740, %f1687;
	mov.f32 	%f1741, %f1687;
	mov.f32 	%f1742, %f1687;
	mov.f32 	%f1743, %f1687;
	mov.f32 	%f1744, %f1687;
	mov.f32 	%f1745, %f1687;
	mov.f32 	%f1746, %f1687;
	mov.f32 	%f1747, %f1687;
	mov.f32 	%f1748, %f1687;
	mov.f32 	%f1749, %f1687;
	mov.f32 	%f1750, %f1687;
	mov.f32 	%f1751, %f1687;
	mov.f32 	%f1752, %f1687;
	mov.f32 	%f1753, %f1687;
	mov.f32 	%f1754, %f1687;
	mov.f32 	%f1755, %f1687;
	mov.f32 	%f1756, %f1687;
	mov.f32 	%f1757, %f1687;
	mov.f32 	%f1758, %f1687;
	mov.f32 	%f1759, %f1687;
	mov.f32 	%f1760, %f1687;
	mov.f32 	%f1761, %f1687;
	mov.f32 	%f1762, %f1687;
	mov.f32 	%f1763, %f1687;
	mov.f32 	%f1764, %f1687;
	mov.f32 	%f1765, %f1687;
	mov.f32 	%f1766, %f1687;
	mov.f32 	%f1767, %f1687;
	mov.f32 	%f1768, %f1687;
	mov.f32 	%f1769, %f1687;
	mov.f32 	%f1770, %f1687;
	mov.f32 	%f1771, %f1687;
	mov.f32 	%f1772, %f1687;
	mov.f32 	%f1773, %f1687;
	mov.f32 	%f1774, %f1687;
	mov.f32 	%f1775, %f1687;
	mov.f32 	%f1776, %f1687;
	mov.f32 	%f1777, %f1687;
	mov.f32 	%f1778, %f1687;
	mov.f32 	%f1779, %f1687;
	mov.f32 	%f1780, %f1687;
	mov.f32 	%f1781, %f1687;
	mov.f32 	%f1782, %f1687;
	mov.f32 	%f1783, %f1687;
	mov.f32 	%f1784, %f1687;
	mov.f32 	%f1785, %f1687;
	mov.f32 	%f1786, %f1687;
	mov.f32 	%f1787, %f1687;
	mov.f32 	%f1788, %f1687;
	mov.f32 	%f1789, %f1687;
	mov.f32 	%f1790, %f1687;
	mov.f32 	%f1791, %f1687;
	mov.f32 	%f1792, %f1687;
	mov.f32 	%f1793, %f1687;
	mov.f32 	%f1794, %f1687;
	mov.f32 	%f1795, %f1687;
	mov.f32 	%f1796, %f1687;
	mov.f32 	%f1797, %f1687;
	mov.f32 	%f1798, %f1687;
	mov.f32 	%f1799, %f1687;
	mov.f32 	%f1800, %f1687;
	mov.f32 	%f1801, %f1687;
	mov.f32 	%f1802, %f1687;
	mov.f32 	%f1803, %f1687;
	mov.f32 	%f1804, %f1687;
	mov.f32 	%f1805, %f1687;
	mov.f32 	%f1806, %f1687;
	mov.f32 	%f1807, %f1687;
	mov.f32 	%f1808, %f1687;
	mov.f32 	%f1809, %f1687;
	mov.f32 	%f1810, %f1687;
	mov.f32 	%f1811, %f1687;
	mov.f32 	%f1812, %f1687;
	mov.f32 	%f1813, %f1687;
	mov.f32 	%f1814, %f1687;
	.loc	1 48 25
	@%p51 bra 	$L__BB0_3;
	.loc	1 0 25
	ld.param.u32 	%r59, [matmul_kernel_param_7];
	ld.param.u64 	%rd164, [matmul_kernel_param_1];
	shr.u32 	%r5, %r4, 5;
	setp.lt.s32 	%p42, %r7, %r57;
	setp.lt.s32 	%p43, %r8, %r57;
	setp.lt.s32 	%p44, %r9, %r57;
	setp.lt.s32 	%p45, %r10, %r57;
	setp.lt.s32 	%p46, %r11, %r57;
	setp.lt.s32 	%p47, %r12, %r57;
	setp.lt.s32 	%p48, %r13, %r57;
	setp.lt.s32 	%p49, %r14, %r57;
	and.pred  	%p54, %p42, %p50;
	and.pred  	%p59, %p43, %p50;
	and.pred  	%p64, %p44, %p50;
	and.pred  	%p69, %p45, %p50;
	and.pred  	%p74, %p46, %p50;
	and.pred  	%p79, %p47, %p50;
	and.pred  	%p84, %p48, %p50;
	and.pred  	%p89, %p49, %p50;
	.loc	1 61 28
	shl.b32 	%r168, %r59, 5;
	add.s32 	%r26, %r57, -64;
	shl.b32 	%r169, %r16, 5;
	shl.b32 	%r170, %r4, 4;
	and.b32  	%r171, %r170, 16;
	or.b32  	%r172, %r7, %r171;
	or.b32  	%r173, %r169, %r172;
	shl.b32 	%r174, %r173, 2;
	add.s32 	%r176, %r141, 49152;
	add.s32 	%r27, %r176, %r174;
	add.s32 	%r28, %r27, 16;
	add.s32 	%r29, %r27, 32;
	add.s32 	%r30, %r27, 48;
	or.b32  	%r177, %r173, 32;
	or.b32  	%r178, %r173, 64;
	or.b32  	%r179, %r173, 96;
	xor.b32  	%r180, %r173, 16;
	shl.b32 	%r181, %r180, 2;
	add.s32 	%r32, %r176, %r181;
	xor.b32  	%r182, %r177, 20;
	shl.b32 	%r183, %r182, 2;
	add.s32 	%r33, %r176, %r183;
	xor.b32  	%r184, %r178, 24;
	shl.b32 	%r185, %r184, 2;
	add.s32 	%r34, %r176, %r185;
	xor.b32  	%r186, %r179, 28;
	shl.b32 	%r187, %r186, 2;
	add.s32 	%r35, %r176, %r187;
	xor.b32  	%r188, %r173, 20;
	shl.b32 	%r189, %r188, 2;
	add.s32 	%r36, %r176, %r189;
	xor.b32  	%r190, %r177, 16;
	shl.b32 	%r191, %r190, 2;
	add.s32 	%r37, %r176, %r191;
	xor.b32  	%r192, %r178, 28;
	shl.b32 	%r193, %r192, 2;
	add.s32 	%r38, %r176, %r193;
	xor.b32  	%r194, %r179, 24;
	shl.b32 	%r195, %r194, 2;
	add.s32 	%r39, %r176, %r195;
	xor.b32  	%r196, %r173, 24;
	shl.b32 	%r197, %r196, 2;
	add.s32 	%r40, %r176, %r197;
	xor.b32  	%r198, %r177, 28;
	shl.b32 	%r199, %r198, 2;
	add.s32 	%r41, %r176, %r199;
	xor.b32  	%r200, %r178, 16;
	shl.b32 	%r201, %r200, 2;
	add.s32 	%r42, %r176, %r201;
	xor.b32  	%r202, %r179, 20;
	shl.b32 	%r203, %r202, 2;
	add.s32 	%r43, %r176, %r203;
	xor.b32  	%r204, %r173, 28;
	shl.b32 	%r205, %r204, 2;
	add.s32 	%r44, %r176, %r205;
	xor.b32  	%r206, %r177, 24;
	shl.b32 	%r207, %r206, 2;
	add.s32 	%r45, %r176, %r207;
	xor.b32  	%r208, %r178, 20;
	shl.b32 	%r209, %r208, 2;
	add.s32 	%r46, %r176, %r209;
	xor.b32  	%r210, %r179, 16;
	shl.b32 	%r211, %r210, 2;
	add.s32 	%r47, %r176, %r211;
	and.b32  	%r48, %r5, 134217724;
	shr.u32 	%r212, %r176, 4;
	cvt.u64.u32 	%rd53, %r212;
	and.b64  	%rd54, %rd53, 16383;
	or.b64  	%rd72, %rd54, 4611686293372403712;
	add.s64 	%rd74, %rd54, 4611686293372403714;
	add.s64 	%rd76, %rd54, 4611686293372403716;
	add.s64 	%rd78, %rd54, 4611686293372403718;
	.loc	1 48 25
	shl.b32 	%r214, %r61, 7;
	mad.lo.s32 	%r215, %r59, %r14, %r214;
	add.s32 	%r216, %r215, %r16;
	shl.b32 	%r217, %r2, 7;
	sub.s32 	%r218, %r216, %r217;
	mul.wide.s32 	%rd5, %r218, 4;
	mul.wide.s32 	%rd6, %r168, 4;
	mad.lo.s32 	%r220, %r59, %r13, %r214;
	add.s32 	%r221, %r220, %r16;
	sub.s32 	%r222, %r221, %r217;
	mul.wide.s32 	%rd7, %r222, 4;
	mad.lo.s32 	%r224, %r59, %r12, %r214;
	add.s32 	%r225, %r224, %r16;
	sub.s32 	%r226, %r225, %r217;
	mul.wide.s32 	%rd8, %r226, 4;
	mad.lo.s32 	%r228, %r59, %r11, %r214;
	add.s32 	%r229, %r228, %r16;
	sub.s32 	%r230, %r229, %r217;
	mul.wide.s32 	%rd9, %r230, 4;
	mad.lo.s32 	%r232, %r59, %r10, %r214;
	add.s32 	%r233, %r232, %r16;
	sub.s32 	%r234, %r233, %r217;
	mul.wide.s32 	%rd10, %r234, 4;
	mad.lo.s32 	%r236, %r59, %r9, %r214;
	add.s32 	%r237, %r236, %r16;
	sub.s32 	%r238, %r237, %r217;
	mul.wide.s32 	%rd11, %r238, 4;
	mad.lo.s32 	%r240, %r59, %r8, %r214;
	add.s32 	%r241, %r240, %r16;
	sub.s32 	%r242, %r241, %r217;
	mul.wide.s32 	%rd12, %r242, 4;
	mad.lo.s32 	%r243, %r7, %r59, %r214;
	add.s32 	%r244, %r243, %r16;
	sub.s32 	%r245, %r244, %r217;
	mul.wide.s32 	%rd13, %r245, 4;
	add.s32 	%r246, %r3, %r6;
	add.s32 	%r247, %r246, 112;
	mad.lo.s32 	%r248, %r58, %r247, %r15;
	mul.wide.s32 	%rd55, %r248, 4;
	add.s64 	%rd14, %rd55, 256;
	add.s32 	%r249, %r246, 96;
	mad.lo.s32 	%r250, %r58, %r249, %r15;
	mul.wide.s32 	%rd56, %r250, 4;
	add.s64 	%rd15, %rd56, 256;
	add.s32 	%r251, %r246, 80;
	mad.lo.s32 	%r252, %r58, %r251, %r15;
	mul.wide.s32 	%rd57, %r252, 4;
	add.s64 	%rd16, %rd57, 256;
	add.s32 	%r253, %r246, 64;
	mad.lo.s32 	%r254, %r58, %r253, %r15;
	mul.wide.s32 	%rd58, %r254, 4;
	add.s64 	%rd17, %rd58, 256;
	add.s32 	%r255, %r246, 48;
	mad.lo.s32 	%r256, %r58, %r255, %r15;
	mul.wide.s32 	%rd59, %r256, 4;
	add.s64 	%rd18, %rd59, 256;
	add.s32 	%r257, %r246, 32;
	mad.lo.s32 	%r258, %r58, %r257, %r15;
	mul.wide.s32 	%rd60, %r258, 4;
	add.s64 	%rd19, %rd60, 256;
	add.s32 	%r259, %r246, 16;
	mad.lo.s32 	%r260, %r58, %r259, %r15;
	mul.wide.s32 	%rd61, %r260, 4;
	add.s64 	%rd20, %rd61, 256;
	mad.lo.s32 	%r261, %r58, %r246, %r15;
	mul.wide.s32 	%rd62, %r261, 4;
	add.s64 	%rd21, %rd62, 256;
	mov.b32 	%r266, 0;
	mov.f32 	%f1680, 0f00000000;
	mov.b32 	%r572, 1;
	mov.b32 	%r571, -1;
	mov.f32 	%f1679, 0f00000001;
	mov.f32 	%f1678, 0f00000020;
	mov.f32 	%f1687, %f1680;
	mov.f32 	%f1688, %f1680;
	mov.f32 	%f1689, %f1680;
	mov.f32 	%f1690, %f1680;
	mov.f32 	%f1691, %f1680;
	mov.f32 	%f1692, %f1680;
	mov.f32 	%f1693, %f1680;
	mov.f32 	%f1694, %f1680;
	mov.f32 	%f1695, %f1680;
	mov.f32 	%f1696, %f1680;
	mov.f32 	%f1697, %f1680;
	mov.f32 	%f1698, %f1680;
	mov.f32 	%f1699, %f1680;
	mov.f32 	%f1700, %f1680;
	mov.f32 	%f1701, %f1680;
	mov.f32 	%f1702, %f1680;
	mov.f32 	%f1703, %f1680;
	mov.f32 	%f1704, %f1680;
	mov.f32 	%f1705, %f1680;
	mov.f32 	%f1706, %f1680;
	mov.f32 	%f1707, %f1680;
	mov.f32 	%f1708, %f1680;
	mov.f32 	%f1709, %f1680;
	mov.f32 	%f1710, %f1680;
	mov.f32 	%f1711, %f1680;
	mov.f32 	%f1712, %f1680;
	mov.f32 	%f1713, %f1680;
	mov.f32 	%f1714, %f1680;
	mov.f32 	%f1715, %f1680;
	mov.f32 	%f1716, %f1680;
	mov.f32 	%f1717, %f1680;
	mov.f32 	%f1718, %f1680;
	mov.f32 	%f1719, %f1680;
	mov.f32 	%f1720, %f1680;
	mov.f32 	%f1721, %f1680;
	mov.f32 	%f1722, %f1680;
	mov.f32 	%f1723, %f1680;
	mov.f32 	%f1724, %f1680;
	mov.f32 	%f1725, %f1680;
	mov.f32 	%f1726, %f1680;
	mov.f32 	%f1727, %f1680;
	mov.f32 	%f1728, %f1680;
	mov.f32 	%f1729, %f1680;
	mov.f32 	%f1730, %f1680;
	mov.f32 	%f1731, %f1680;
	mov.f32 	%f1732, %f1680;
	mov.f32 	%f1733, %f1680;
	mov.f32 	%f1734, %f1680;
	mov.f32 	%f1735, %f1680;
	mov.f32 	%f1736, %f1680;
	mov.f32 	%f1737, %f1680;
	mov.f32 	%f1738, %f1680;
	mov.f32 	%f1739, %f1680;
	mov.f32 	%f1740, %f1680;
	mov.f32 	%f1741, %f1680;
	mov.f32 	%f1742, %f1680;
	mov.f32 	%f1743, %f1680;
	mov.f32 	%f1744, %f1680;
	mov.f32 	%f1745, %f1680;
	mov.f32 	%f1746, %f1680;
	mov.f32 	%f1747, %f1680;
	mov.f32 	%f1748, %f1680;
	mov.f32 	%f1749, %f1680;
	mov.f32 	%f1750, %f1680;
	mov.f32 	%f1751, %f1680;
	mov.f32 	%f1752, %f1680;
	mov.f32 	%f1753, %f1680;
	mov.f32 	%f1754, %f1680;
	mov.f32 	%f1755, %f1680;
	mov.f32 	%f1756, %f1680;
	mov.f32 	%f1757, %f1680;
	mov.f32 	%f1758, %f1680;
	mov.f32 	%f1759, %f1680;
	mov.f32 	%f1760, %f1680;
	mov.f32 	%f1761, %f1680;
	mov.f32 	%f1762, %f1680;
	mov.f32 	%f1763, %f1680;
	mov.f32 	%f1764, %f1680;
	mov.f32 	%f1765, %f1680;
	mov.f32 	%f1766, %f1680;
	mov.f32 	%f1767, %f1680;
	mov.f32 	%f1768, %f1680;
	mov.f32 	%f1769, %f1680;
	mov.f32 	%f1770, %f1680;
	mov.f32 	%f1771, %f1680;
	mov.f32 	%f1772, %f1680;
	mov.f32 	%f1773, %f1680;
	mov.f32 	%f1774, %f1680;
	mov.f32 	%f1775, %f1680;
	mov.f32 	%f1776, %f1680;
	mov.f32 	%f1777, %f1680;
	mov.f32 	%f1778, %f1680;
	mov.f32 	%f1779, %f1680;
	mov.f32 	%f1780, %f1680;
	mov.f32 	%f1781, %f1680;
	mov.f32 	%f1782, %f1680;
	mov.f32 	%f1783, %f1680;
	mov.f32 	%f1784, %f1680;
	mov.f32 	%f1785, %f1680;
	mov.f32 	%f1786, %f1680;
	mov.f32 	%f1787, %f1680;
	mov.f32 	%f1788, %f1680;
	mov.f32 	%f1789, %f1680;
	mov.f32 	%f1790, %f1680;
	mov.f32 	%f1791, %f1680;
	mov.f32 	%f1792, %f1680;
	mov.f32 	%f1793, %f1680;
	mov.f32 	%f1794, %f1680;
	mov.f32 	%f1795, %f1680;
	mov.f32 	%f1796, %f1680;
	mov.f32 	%f1797, %f1680;
	mov.f32 	%f1798, %f1680;
	mov.f32 	%f1799, %f1680;
	mov.f32 	%f1800, %f1680;
	mov.f32 	%f1801, %f1680;
	mov.f32 	%f1802, %f1680;
	mov.f32 	%f1803, %f1680;
	mov.f32 	%f1804, %f1680;
	mov.f32 	%f1805, %f1680;
	mov.f32 	%f1806, %f1680;
	mov.f32 	%f1807, %f1680;
	mov.f32 	%f1808, %f1680;
	mov.f32 	%f1809, %f1680;
	mov.f32 	%f1810, %f1680;
	mov.f32 	%f1811, %f1680;
	mov.f32 	%f1812, %f1680;
	mov.f32 	%f1813, %f1680;
	mov.f32 	%f1814, %f1680;
	mov.u32 	%r573, %r266;
$L__BB0_2:
	add.s64 	%rd70, %rd164, %rd5;
	add.s64 	%rd69, %rd164, %rd7;
	add.s64 	%rd68, %rd164, %rd8;
	add.s64 	%rd67, %rd164, %rd9;
	add.s64 	%rd66, %rd164, %rd10;
	add.s64 	%rd65, %rd164, %rd11;
	add.s64 	%rd64, %rd164, %rd12;
	add.s64 	%rd63, %rd164, %rd13;
	setp.lt.s32 	%p102, %r573, %r26;
	add.s32 	%r342, %r571, 1;
	setp.lt.s32 	%p103, %r342, 3;
	selp.b32 	%r571, %r342, 0, %p103;
	.loc	1 50 12
	// begin inline asm
	cp.async.wait_group 0x1;
	// end inline asm
	bar.sync 	0;
	shl.b32 	%r343, %r571, 14;
	add.s32 	%r345, %r141, %r343;
	.loc	1 55 12
	// begin inline asm
	mov.u32 %r262, 0x0;
	mov.u32 %r263, 0x0;
	mov.u32 %r264, 0x0;
	mov.u32 %r265, 0x0;
	@%p54 ld.global.v4.b32 { %r262, %r263, %r264, %r265 }, [ %rd63 + 0 ];
	@!%p54 mov.u32 %r262, %r266;
	@!%p54 mov.u32 %r263, %r266;
	@!%p54 mov.u32 %r264, %r266;
	@!%p54 mov.u32 %r265, %r266;
	// end inline asm
	// begin inline asm
	mov.u32 %r270, 0x0;
	mov.u32 %r271, 0x0;
	mov.u32 %r272, 0x0;
	mov.u32 %r273, 0x0;
	@%p59 ld.global.v4.b32 { %r270, %r271, %r272, %r273 }, [ %rd64 + 0 ];
	@!%p59 mov.u32 %r270, %r266;
	@!%p59 mov.u32 %r271, %r266;
	@!%p59 mov.u32 %r272, %r266;
	@!%p59 mov.u32 %r273, %r266;
	// end inline asm
	// begin inline asm
	mov.u32 %r278, 0x0;
	mov.u32 %r279, 0x0;
	mov.u32 %r280, 0x0;
	mov.u32 %r281, 0x0;
	@%p64 ld.global.v4.b32 { %r278, %r279, %r280, %r281 }, [ %rd65 + 0 ];
	@!%p64 mov.u32 %r278, %r266;
	@!%p64 mov.u32 %r279, %r266;
	@!%p64 mov.u32 %r280, %r266;
	@!%p64 mov.u32 %r281, %r266;
	// end inline asm
	// begin inline asm
	mov.u32 %r286, 0x0;
	mov.u32 %r287, 0x0;
	mov.u32 %r288, 0x0;
	mov.u32 %r289, 0x0;
	@%p69 ld.global.v4.b32 { %r286, %r287, %r288, %r289 }, [ %rd66 + 0 ];
	@!%p69 mov.u32 %r286, %r266;
	@!%p69 mov.u32 %r287, %r266;
	@!%p69 mov.u32 %r288, %r266;
	@!%p69 mov.u32 %r289, %r266;
	// end inline asm
	// begin inline asm
	mov.u32 %r294, 0x0;
	mov.u32 %r295, 0x0;
	mov.u32 %r296, 0x0;
	mov.u32 %r297, 0x0;
	@%p74 ld.global.v4.b32 { %r294, %r295, %r296, %r297 }, [ %rd67 + 0 ];
	@!%p74 mov.u32 %r294, %r266;
	@!%p74 mov.u32 %r295, %r266;
	@!%p74 mov.u32 %r296, %r266;
	@!%p74 mov.u32 %r297, %r266;
	// end inline asm
	// begin inline asm
	mov.u32 %r302, 0x0;
	mov.u32 %r303, 0x0;
	mov.u32 %r304, 0x0;
	mov.u32 %r305, 0x0;
	@%p79 ld.global.v4.b32 { %r302, %r303, %r304, %r305 }, [ %rd68 + 0 ];
	@!%p79 mov.u32 %r302, %r266;
	@!%p79 mov.u32 %r303, %r266;
	@!%p79 mov.u32 %r304, %r266;
	@!%p79 mov.u32 %r305, %r266;
	// end inline asm
	// begin inline asm
	mov.u32 %r310, 0x0;
	mov.u32 %r311, 0x0;
	mov.u32 %r312, 0x0;
	mov.u32 %r313, 0x0;
	@%p84 ld.global.v4.b32 { %r310, %r311, %r312, %r313 }, [ %rd69 + 0 ];
	@!%p84 mov.u32 %r310, %r266;
	@!%p84 mov.u32 %r311, %r266;
	@!%p84 mov.u32 %r312, %r266;
	@!%p84 mov.u32 %r313, %r266;
	// end inline asm
	// begin inline asm
	mov.u32 %r318, 0x0;
	mov.u32 %r319, 0x0;
	mov.u32 %r320, 0x0;
	mov.u32 %r321, 0x0;
	@%p89 ld.global.v4.b32 { %r318, %r319, %r320, %r321 }, [ %rd70 + 0 ];
	@!%p89 mov.u32 %r318, %r266;
	@!%p89 mov.u32 %r319, %r266;
	@!%p89 mov.u32 %r320, %r266;
	@!%p89 mov.u32 %r321, %r266;
	// end inline asm
	st.shared.u32 	[%r27], %r262;
	st.shared.u32 	[%r28+128], %r263;
	st.shared.u32 	[%r29+256], %r264;
	st.shared.u32 	[%r30+384], %r265;
	st.shared.u32 	[%r27+16], %r270;
	st.shared.u32 	[%r27+128], %r271;
	st.shared.u32 	[%r30+256], %r272;
	st.shared.u32 	[%r29+384], %r273;
	st.shared.u32 	[%r27+32], %r278;
	st.shared.u32 	[%r30+128], %r279;
	st.shared.u32 	[%r27+256], %r280;
	st.shared.u32 	[%r28+384], %r281;
	st.shared.u32 	[%r27+48], %r286;
	st.shared.u32 	[%r29+128], %r287;
	st.shared.u32 	[%r28+256], %r288;
	st.shared.u32 	[%r27+384], %r289;
	st.shared.u32 	[%r32], %r294;
	st.shared.u32 	[%r33], %r295;
	st.shared.u32 	[%r34], %r296;
	st.shared.u32 	[%r35], %r297;
	st.shared.u32 	[%r36], %r302;
	st.shared.u32 	[%r37], %r303;
	st.shared.u32 	[%r38], %r304;
	st.shared.u32 	[%r39], %r305;
	st.shared.u32 	[%r40], %r310;
	st.shared.u32 	[%r41], %r311;
	st.shared.u32 	[%r42], %r312;
	st.shared.u32 	[%r43], %r313;
	st.shared.u32 	[%r44], %r318;
	st.shared.u32 	[%r45], %r319;
	st.shared.u32 	[%r46], %r320;
	st.shared.u32 	[%r47], %r321;
	.loc	1 59 25
	// begin inline asm
	fence.proxy.async.shared::cta;
	// end inline asm
	bar.sync 	0;
	shfl.sync.idx.b32	%r346, %r48, 0, 31, -1;
	// begin inline asm
	wgmma.fence.sync.aligned;
	// end inline asm
	shl.b32 	%r347, %r346, 7;
	and.b32  	%r348, %r347, 384;
	cvt.u64.u32 	%rd95, %r348;
	shr.u32 	%r349, %r345, 4;
	cvt.u64.u32 	%rd96, %r349;
	and.b64  	%rd97, %rd96, 16383;
	add.s64 	%rd98, %rd97, %rd95;
	or.b64  	%rd71, %rd98, 4611686293372403712;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n128k8.f32.tf32.tf32 {%f1687,%f1688,%f1689,%f1690,%f1691,%f1692,%f1693,%f1694,%f1695,%f1696,%f1697,%f1698,%f1699,%f1700,%f1701,%f1702,%f1703,%f1704,%f1705,%f1706,%f1707,%f1708,%f1709,%f1710,%f1711,%f1712,%f1713,%f1714,%f1715,%f1716,%f1717,%f1718,%f1719,%f1720,%f1721,%f1722,%f1723,%f1724,%f1725,%f1726,%f1727,%f1728,%f1729,%f1730,%f1731,%f1732,%f1733,%f1734,%f1735,%f1736,%f1737,%f1738,%f1739,%f1740,%f1741,%f1742,%f1743,%f1744,%f1745,%f1746,%f1747,%f1748,%f1749,%f1750}, %rd71, %rd72, 1, 1, 1;
	// end inline asm
	add.s64 	%rd73, %rd98, 4611686293372403714;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n128k8.f32.tf32.tf32 {%f1687,%f1688,%f1689,%f1690,%f1691,%f1692,%f1693,%f1694,%f1695,%f1696,%f1697,%f1698,%f1699,%f1700,%f1701,%f1702,%f1703,%f1704,%f1705,%f1706,%f1707,%f1708,%f1709,%f1710,%f1711,%f1712,%f1713,%f1714,%f1715,%f1716,%f1717,%f1718,%f1719,%f1720,%f1721,%f1722,%f1723,%f1724,%f1725,%f1726,%f1727,%f1728,%f1729,%f1730,%f1731,%f1732,%f1733,%f1734,%f1735,%f1736,%f1737,%f1738,%f1739,%f1740,%f1741,%f1742,%f1743,%f1744,%f1745,%f1746,%f1747,%f1748,%f1749,%f1750}, %rd73, %rd74, 1, 1, 1;
	// end inline asm
	add.s64 	%rd75, %rd98, 4611686293372403716;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n128k8.f32.tf32.tf32 {%f1687,%f1688,%f1689,%f1690,%f1691,%f1692,%f1693,%f1694,%f1695,%f1696,%f1697,%f1698,%f1699,%f1700,%f1701,%f1702,%f1703,%f1704,%f1705,%f1706,%f1707,%f1708,%f1709,%f1710,%f1711,%f1712,%f1713,%f1714,%f1715,%f1716,%f1717,%f1718,%f1719,%f1720,%f1721,%f1722,%f1723,%f1724,%f1725,%f1726,%f1727,%f1728,%f1729,%f1730,%f1731,%f1732,%f1733,%f1734,%f1735,%f1736,%f1737,%f1738,%f1739,%f1740,%f1741,%f1742,%f1743,%f1744,%f1745,%f1746,%f1747,%f1748,%f1749,%f1750}, %rd75, %rd76, 1, 1, 1;
	// end inline asm
	add.s64 	%rd77, %rd98, 4611686293372403718;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n128k8.f32.tf32.tf32 {%f1687,%f1688,%f1689,%f1690,%f1691,%f1692,%f1693,%f1694,%f1695,%f1696,%f1697,%f1698,%f1699,%f1700,%f1701,%f1702,%f1703,%f1704,%f1705,%f1706,%f1707,%f1708,%f1709,%f1710,%f1711,%f1712,%f1713,%f1714,%f1715,%f1716,%f1717,%f1718,%f1719,%f1720,%f1721,%f1722,%f1723,%f1724,%f1725,%f1726,%f1727,%f1728,%f1729,%f1730,%f1731,%f1732,%f1733,%f1734,%f1735,%f1736,%f1737,%f1738,%f1739,%f1740,%f1741,%f1742,%f1743,%f1744,%f1745,%f1746,%f1747,%f1748,%f1749,%f1750}, %rd77, %rd78, 1, 1, 1;
	// end inline asm
	add.s64 	%rd79, %rd98, 4611686293372404224;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n128k8.f32.tf32.tf32 {%f1751,%f1752,%f1753,%f1754,%f1755,%f1756,%f1757,%f1758,%f1759,%f1760,%f1761,%f1762,%f1763,%f1764,%f1765,%f1766,%f1767,%f1768,%f1769,%f1770,%f1771,%f1772,%f1773,%f1774,%f1775,%f1776,%f1777,%f1778,%f1779,%f1780,%f1781,%f1782,%f1783,%f1784,%f1785,%f1786,%f1787,%f1788,%f1789,%f1790,%f1791,%f1792,%f1793,%f1794,%f1795,%f1796,%f1797,%f1798,%f1799,%f1800,%f1801,%f1802,%f1803,%f1804,%f1805,%f1806,%f1807,%f1808,%f1809,%f1810,%f1811,%f1812,%f1813,%f1814}, %rd79, %rd72, 1, 1, 1;
	// end inline asm
	add.s64 	%rd81, %rd98, 4611686293372404226;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n128k8.f32.tf32.tf32 {%f1751,%f1752,%f1753,%f1754,%f1755,%f1756,%f1757,%f1758,%f1759,%f1760,%f1761,%f1762,%f1763,%f1764,%f1765,%f1766,%f1767,%f1768,%f1769,%f1770,%f1771,%f1772,%f1773,%f1774,%f1775,%f1776,%f1777,%f1778,%f1779,%f1780,%f1781,%f1782,%f1783,%f1784,%f1785,%f1786,%f1787,%f1788,%f1789,%f1790,%f1791,%f1792,%f1793,%f1794,%f1795,%f1796,%f1797,%f1798,%f1799,%f1800,%f1801,%f1802,%f1803,%f1804,%f1805,%f1806,%f1807,%f1808,%f1809,%f1810,%f1811,%f1812,%f1813,%f1814}, %rd81, %rd74, 1, 1, 1;
	// end inline asm
	add.s64 	%rd83, %rd98, 4611686293372404228;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n128k8.f32.tf32.tf32 {%f1751,%f1752,%f1753,%f1754,%f1755,%f1756,%f1757,%f1758,%f1759,%f1760,%f1761,%f1762,%f1763,%f1764,%f1765,%f1766,%f1767,%f1768,%f1769,%f1770,%f1771,%f1772,%f1773,%f1774,%f1775,%f1776,%f1777,%f1778,%f1779,%f1780,%f1781,%f1782,%f1783,%f1784,%f1785,%f1786,%f1787,%f1788,%f1789,%f1790,%f1791,%f1792,%f1793,%f1794,%f1795,%f1796,%f1797,%f1798,%f1799,%f1800,%f1801,%f1802,%f1803,%f1804,%f1805,%f1806,%f1807,%f1808,%f1809,%f1810,%f1811,%f1812,%f1813,%f1814}, %rd83, %rd76, 1, 1, 1;
	// end inline asm
	add.s64 	%rd85, %rd98, 4611686293372404230;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n128k8.f32.tf32.tf32 {%f1751,%f1752,%f1753,%f1754,%f1755,%f1756,%f1757,%f1758,%f1759,%f1760,%f1761,%f1762,%f1763,%f1764,%f1765,%f1766,%f1767,%f1768,%f1769,%f1770,%f1771,%f1772,%f1773,%f1774,%f1775,%f1776,%f1777,%f1778,%f1779,%f1780,%f1781,%f1782,%f1783,%f1784,%f1785,%f1786,%f1787,%f1788,%f1789,%f1790,%f1791,%f1792,%f1793,%f1794,%f1795,%f1796,%f1797,%f1798,%f1799,%f1800,%f1801,%f1802,%f1803,%f1804,%f1805,%f1806,%f1807,%f1808,%f1809,%f1810,%f1811,%f1812,%f1813,%f1814}, %rd85, %rd78, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.commit_group.sync.aligned;
	// end inline asm
	mov.b32 	%f1539, %r345;
	mov.b32 	%f1544, %r176;
	mov.f32 	%f1546, %f1678;
	mov.f32 	%f1540, %f1678;
	mov.f32 	%f1541, %f1679;
	mov.f32 	%f1542, %f1680;
	mov.f32 	%f1543, %f1680;
	mov.f32 	%f1547, %f1680;
	mov.f32 	%f1548, %f1680;
	mov.f32 	%f1545, %f1679;
	// begin inline asm
	// wait for regs: %f1687,%f1688,%f1689,%f1690,%f1691,%f1692,%f1693,%f1694,%f1695,%f1696,%f1697,%f1698,%f1699,%f1700,%f1701,%f1702,%f1703,%f1704,%f1705,%f1706,%f1707,%f1708,%f1709,%f1710,%f1711,%f1712,%f1713,%f1714,%f1715,%f1716,%f1717,%f1718,%f1719,%f1720,%f1721,%f1722,%f1723,%f1724,%f1725,%f1726,%f1727,%f1728,%f1729,%f1730,%f1731,%f1732,%f1733,%f1734,%f1735,%f1736,%f1737,%f1738,%f1739,%f1740,%f1741,%f1742,%f1743,%f1744,%f1745,%f1746,%f1747,%f1748,%f1749,%f1750,%f1751,%f1752,%f1753,%f1754,%f1755,%f1756,%f1757,%f1758,%f1759,%f1760,%f1761,%f1762,%f1763,%f1764,%f1765,%f1766,%f1767,%f1768,%f1769,%f1770,%f1771,%f1772,%f1773,%f1774,%f1775,%f1776,%f1777,%f1778,%f1779,%f1780,%f1781,%f1782,%f1783,%f1784,%f1785,%f1786,%f1787,%f1788,%f1789,%f1790,%f1791,%f1792,%f1793,%f1794,%f1795,%f1796,%f1797,%f1798,%f1799,%f1800,%f1801,%f1802,%f1803,%f1804,%f1805,%f1806,%f1807,%f1808,%f1809,%f1810,%f1811,%f1812,%f1813,%f1814,%f1539,%f1540,%f1541,%f1542,%f1543,%f1544,%f1545,%f1546,%f1547,%f1548
	wgmma.wait_group.sync.aligned 0;
	// end inline asm
	.loc	1 60 18
	add.s64 	%rd87, %rd163, %rd21;
	add.s64 	%rd88, %rd163, %rd20;
	add.s64 	%rd89, %rd163, %rd19;
	add.s64 	%rd90, %rd163, %rd18;
	add.s64 	%rd91, %rd163, %rd17;
	add.s64 	%rd92, %rd163, %rd16;
	add.s64 	%rd93, %rd163, %rd15;
	.loc	1 48 25
	add.s64 	%rd94, %rd163, %rd14;
	add.s32 	%r351, %r572, 1;
	setp.lt.s32 	%p104, %r351, 3;
	selp.b32 	%r572, %r351, 0, %p104;
	.loc	1 50 12
	shl.b32 	%r352, %r572, 14;
	add.s32 	%r353, %r141, %r352;
	bar.sync 	0;
	add.s32 	%r326, %r353, %r140;
	add.s32 	%r328, %r353, %r143;
	add.s32 	%r330, %r353, %r145;
	add.s32 	%r332, %r353, %r147;
	add.s32 	%r334, %r353, %r149;
	add.s32 	%r336, %r353, %r151;
	add.s32 	%r338, %r353, %r153;
	add.s32 	%r340, %r353, %r155;
	selp.b32 	%r362, 16, 0, %p102;
	selp.b32 	%r327, %r362, 0, %p1;
	// begin inline asm
	@%p17 cp.async.cg.shared.global [ %r326 + 0 ], [ %rd87 + 0 ], 0x10, %r327;
	// end inline asm
	selp.b32 	%r329, %r362, 0, %p2;
	// begin inline asm
	@%p17 cp.async.cg.shared.global [ %r328 + 0 ], [ %rd88 + 0 ], 0x10, %r329;
	// end inline asm
	selp.b32 	%r331, %r362, 0, %p3;
	// begin inline asm
	@%p17 cp.async.cg.shared.global [ %r330 + 0 ], [ %rd89 + 0 ], 0x10, %r331;
	// end inline asm
	selp.b32 	%r333, %r362, 0, %p4;
	// begin inline asm
	@%p17 cp.async.cg.shared.global [ %r332 + 0 ], [ %rd90 + 0 ], 0x10, %r333;
	// end inline asm
	selp.b32 	%r335, %r362, 0, %p5;
	// begin inline asm
	@%p17 cp.async.cg.shared.global [ %r334 + 0 ], [ %rd91 + 0 ], 0x10, %r335;
	// end inline asm
	selp.b32 	%r337, %r362, 0, %p6;
	// begin inline asm
	@%p17 cp.async.cg.shared.global [ %r336 + 0 ], [ %rd92 + 0 ], 0x10, %r337;
	// end inline asm
	selp.b32 	%r339, %r362, 0, %p7;
	// begin inline asm
	@%p17 cp.async.cg.shared.global [ %r338 + 0 ], [ %rd93 + 0 ], 0x10, %r339;
	// end inline asm
	selp.b32 	%r341, %r362, 0, %p8;
	// begin inline asm
	@%p17 cp.async.cg.shared.global [ %r340 + 0 ], [ %rd94 + 0 ], 0x10, %r341;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	.loc	1 48 25
	add.s32 	%r573, %r573, 32;
	add.s64 	%rd164, %rd164, %rd6;
	add.s64 	%rd163, %rd163, 128;
	setp.lt.s32 	%p105, %r573, %r57;
	@%p105 bra 	$L__BB0_2;
$L__BB0_3:
	.loc	1 34 44
	or.b32  	%r491, %r3, %r7;
	.loc	1 34 31
	or.b32  	%r492, %r491, 124;
	or.b32  	%r493, %r491, 120;
	or.b32  	%r494, %r491, 116;
	or.b32  	%r495, %r491, 112;
	or.b32  	%r496, %r491, 108;
	or.b32  	%r497, %r491, 104;
	or.b32  	%r498, %r491, 100;
	or.b32  	%r499, %r491, 96;
	or.b32  	%r500, %r491, 92;
	or.b32  	%r501, %r491, 88;
	or.b32  	%r502, %r491, 84;
	or.b32  	%r503, %r491, 80;
	or.b32  	%r504, %r491, 76;
	or.b32  	%r505, %r491, 72;
	or.b32  	%r506, %r491, 68;
	or.b32  	%r507, %r491, 64;
	or.b32  	%r508, %r491, 60;
	or.b32  	%r509, %r491, 56;
	or.b32  	%r510, %r491, 52;
	or.b32  	%r511, %r491, 48;
	or.b32  	%r512, %r491, 44;
	or.b32  	%r513, %r491, 40;
	or.b32  	%r514, %r491, 36;
	or.b32  	%r515, %r491, 32;
	or.b32  	%r516, %r3, %r14;
	or.b32  	%r517, %r3, %r13;
	or.b32  	%r518, %r3, %r12;
	or.b32  	%r519, %r3, %r11;
	or.b32  	%r520, %r3, %r10;
	or.b32  	%r521, %r3, %r9;
	or.b32  	%r522, %r3, %r8;
	.loc	1 34 44
	and.b32  	%r523, %r4, 31;
	.loc	1 48 25
	// begin inline asm
	cp.async.wait_group 0x0;
	// end inline asm
	bar.sync 	0;
	.loc	1 66 40
	shl.b32 	%r524, %r60, 5;
	shl.b32 	%r525, %r60, 2;
	.loc	1 66 52
	mad.lo.s32 	%r526, %r491, %r60, %r17;
	mad.lo.s32 	%r527, %r522, %r60, %r17;
	mad.lo.s32 	%r528, %r521, %r60, %r17;
	mad.lo.s32 	%r529, %r520, %r60, %r17;
	mad.lo.s32 	%r530, %r519, %r60, %r17;
	mad.lo.s32 	%r531, %r518, %r60, %r17;
	mad.lo.s32 	%r532, %r517, %r60, %r17;
	mad.lo.s32 	%r533, %r516, %r60, %r17;
	add.s32 	%r534, %r526, %r524;
	add.s32 	%r535, %r534, %r525;
	add.s32 	%r536, %r535, %r525;
	add.s32 	%r537, %r536, %r525;
	add.s32 	%r538, %r537, %r525;
	add.s32 	%r539, %r538, %r525;
	add.s32 	%r540, %r539, %r525;
	add.s32 	%r541, %r540, %r525;
	add.s32 	%r542, %r541, %r525;
	add.s32 	%r543, %r542, %r525;
	add.s32 	%r544, %r543, %r525;
	add.s32 	%r545, %r544, %r525;
	add.s32 	%r546, %r545, %r525;
	add.s32 	%r547, %r546, %r525;
	add.s32 	%r548, %r547, %r525;
	add.s32 	%r549, %r548, %r525;
	add.s32 	%r550, %r549, %r525;
	add.s32 	%r551, %r550, %r525;
	add.s32 	%r552, %r551, %r525;
	add.s32 	%r553, %r552, %r525;
	add.s32 	%r554, %r553, %r525;
	add.s32 	%r555, %r554, %r525;
	add.s32 	%r556, %r555, %r525;
	add.s32 	%r557, %r556, %r525;
	.loc	1 66 22
	mul.wide.s32 	%rd131, %r526, 4;
	add.s64 	%rd99, %rd28, %rd131;
	mul.wide.s32 	%rd132, %r527, 4;
	add.s64 	%rd100, %rd28, %rd132;
	mul.wide.s32 	%rd133, %r528, 4;
	add.s64 	%rd101, %rd28, %rd133;
	mul.wide.s32 	%rd134, %r529, 4;
	add.s64 	%rd102, %rd28, %rd134;
	mul.wide.s32 	%rd135, %r530, 4;
	add.s64 	%rd103, %rd28, %rd135;
	mul.wide.s32 	%rd136, %r531, 4;
	add.s64 	%rd104, %rd28, %rd136;
	mul.wide.s32 	%rd137, %r532, 4;
	add.s64 	%rd105, %rd28, %rd137;
	mul.wide.s32 	%rd138, %r533, 4;
	add.s64 	%rd106, %rd28, %rd138;
	mul.wide.s32 	%rd139, %r534, 4;
	add.s64 	%rd107, %rd28, %rd139;
	mul.wide.s32 	%rd140, %r535, 4;
	add.s64 	%rd108, %rd28, %rd140;
	mul.wide.s32 	%rd141, %r536, 4;
	add.s64 	%rd109, %rd28, %rd141;
	mul.wide.s32 	%rd142, %r537, 4;
	add.s64 	%rd110, %rd28, %rd142;
	mul.wide.s32 	%rd143, %r538, 4;
	add.s64 	%rd111, %rd28, %rd143;
	mul.wide.s32 	%rd144, %r539, 4;
	add.s64 	%rd112, %rd28, %rd144;
	mul.wide.s32 	%rd145, %r540, 4;
	add.s64 	%rd113, %rd28, %rd145;
	mul.wide.s32 	%rd146, %r541, 4;
	add.s64 	%rd114, %rd28, %rd146;
	mul.wide.s32 	%rd147, %r542, 4;
	add.s64 	%rd115, %rd28, %rd147;
	mul.wide.s32 	%rd148, %r543, 4;
	add.s64 	%rd116, %rd28, %rd148;
	mul.wide.s32 	%rd149, %r544, 4;
	add.s64 	%rd117, %rd28, %rd149;
	mul.wide.s32 	%rd150, %r545, 4;
	add.s64 	%rd118, %rd28, %rd150;
	mul.wide.s32 	%rd151, %r546, 4;
	add.s64 	%rd119, %rd28, %rd151;
	mul.wide.s32 	%rd152, %r547, 4;
	add.s64 	%rd120, %rd28, %rd152;
	mul.wide.s32 	%rd153, %r548, 4;
	add.s64 	%rd121, %rd28, %rd153;
	mul.wide.s32 	%rd154, %r549, 4;
	add.s64 	%rd122, %rd28, %rd154;
	mul.wide.s32 	%rd155, %r550, 4;
	add.s64 	%rd123, %rd28, %rd155;
	mul.wide.s32 	%rd156, %r551, 4;
	add.s64 	%rd124, %rd28, %rd156;
	mul.wide.s32 	%rd157, %r552, 4;
	add.s64 	%rd125, %rd28, %rd157;
	mul.wide.s32 	%rd158, %r553, 4;
	add.s64 	%rd126, %rd28, %rd158;
	mul.wide.s32 	%rd159, %r554, 4;
	add.s64 	%rd127, %rd28, %rd159;
	mul.wide.s32 	%rd160, %r555, 4;
	add.s64 	%rd128, %rd28, %rd160;
	mul.wide.s32 	%rd161, %r556, 4;
	add.s64 	%rd129, %rd28, %rd161;
	mul.wide.s32 	%rd162, %r557, 4;
	add.s64 	%rd130, %rd28, %rd162;
	.loc	1 70 32
	setp.lt.s32 	%p139, %r491, %r55;
	setp.lt.s32 	%p140, %r522, %r55;
	setp.lt.s32 	%p141, %r521, %r55;
	setp.lt.s32 	%p142, %r520, %r55;
	setp.lt.s32 	%p143, %r519, %r55;
	setp.lt.s32 	%p144, %r518, %r55;
	setp.lt.s32 	%p145, %r517, %r55;
	setp.lt.s32 	%p146, %r516, %r55;
	setp.lt.s32 	%p147, %r515, %r55;
	setp.lt.s32 	%p148, %r514, %r55;
	setp.lt.s32 	%p149, %r513, %r55;
	setp.lt.s32 	%p150, %r512, %r55;
	setp.lt.s32 	%p151, %r511, %r55;
	setp.lt.s32 	%p152, %r510, %r55;
	setp.lt.s32 	%p153, %r509, %r55;
	setp.lt.s32 	%p154, %r508, %r55;
	setp.lt.s32 	%p155, %r507, %r55;
	setp.lt.s32 	%p156, %r506, %r55;
	setp.lt.s32 	%p157, %r505, %r55;
	setp.lt.s32 	%p158, %r504, %r55;
	setp.lt.s32 	%p159, %r503, %r55;
	setp.lt.s32 	%p160, %r502, %r55;
	setp.lt.s32 	%p161, %r501, %r55;
	setp.lt.s32 	%p162, %r500, %r55;
	setp.lt.s32 	%p163, %r499, %r55;
	setp.lt.s32 	%p164, %r498, %r55;
	setp.lt.s32 	%p165, %r497, %r55;
	setp.lt.s32 	%p166, %r496, %r55;
	setp.lt.s32 	%p167, %r495, %r55;
	setp.lt.s32 	%p168, %r494, %r55;
	setp.lt.s32 	%p169, %r493, %r55;
	setp.lt.s32 	%p170, %r492, %r55;
	.loc	1 70 38
	and.pred  	%p106, %p50, %p139;
	and.pred  	%p107, %p50, %p140;
	and.pred  	%p108, %p50, %p141;
	and.pred  	%p109, %p50, %p142;
	and.pred  	%p110, %p50, %p143;
	and.pred  	%p111, %p50, %p144;
	and.pred  	%p112, %p50, %p145;
	and.pred  	%p113, %p50, %p146;
	and.pred  	%p114, %p147, %p50;
	and.pred  	%p115, %p148, %p50;
	and.pred  	%p116, %p149, %p50;
	and.pred  	%p117, %p150, %p50;
	and.pred  	%p118, %p151, %p50;
	and.pred  	%p119, %p152, %p50;
	and.pred  	%p120, %p153, %p50;
	and.pred  	%p121, %p154, %p50;
	and.pred  	%p122, %p155, %p50;
	and.pred  	%p123, %p156, %p50;
	and.pred  	%p124, %p157, %p50;
	and.pred  	%p125, %p158, %p50;
	and.pred  	%p126, %p159, %p50;
	and.pred  	%p127, %p160, %p50;
	and.pred  	%p128, %p161, %p50;
	and.pred  	%p129, %p162, %p50;
	and.pred  	%p130, %p163, %p50;
	and.pred  	%p131, %p164, %p50;
	and.pred  	%p132, %p165, %p50;
	and.pred  	%p133, %p166, %p50;
	and.pred  	%p134, %p167, %p50;
	and.pred  	%p135, %p168, %p50;
	and.pred  	%p136, %p169, %p50;
	and.pred  	%p137, %p170, %p50;
	.loc	1 69 8
	bfe.u32 	%r558, %r4, 2, 3;
	shl.b32 	%r559, %r4, 1;
	and.b32  	%r560, %r559, 6;
	shl.b32 	%r561, %r7, 4;
	or.b32  	%r562, %r561, %r558;
	mad.lo.s32 	%r563, %r562, 132, %r560;
	shl.b32 	%r564, %r563, 2;
	add.s32 	%r566, %r141, %r564;
	st.shared.v2.f32 	[%r566], {%f1687, %f1688};
	st.shared.v2.f32 	[%r566+4224], {%f1689, %f1690};
	st.shared.v2.f32 	[%r566+32], {%f1691, %f1692};
	st.shared.v2.f32 	[%r566+4256], {%f1693, %f1694};
	st.shared.v2.f32 	[%r566+64], {%f1695, %f1696};
	st.shared.v2.f32 	[%r566+4288], {%f1697, %f1698};
	st.shared.v2.f32 	[%r566+96], {%f1699, %f1700};
	st.shared.v2.f32 	[%r566+4320], {%f1701, %f1702};
	st.shared.v2.f32 	[%r566+128], {%f1703, %f1704};
	st.shared.v2.f32 	[%r566+4352], {%f1705, %f1706};
	st.shared.v2.f32 	[%r566+160], {%f1707, %f1708};
	st.shared.v2.f32 	[%r566+4384], {%f1709, %f1710};
	st.shared.v2.f32 	[%r566+192], {%f1711, %f1712};
	st.shared.v2.f32 	[%r566+4416], {%f1713, %f1714};
	st.shared.v2.f32 	[%r566+224], {%f1715, %f1716};
	st.shared.v2.f32 	[%r566+4448], {%f1717, %f1718};
	st.shared.v2.f32 	[%r566+256], {%f1719, %f1720};
	st.shared.v2.f32 	[%r566+4480], {%f1721, %f1722};
	st.shared.v2.f32 	[%r566+288], {%f1723, %f1724};
	st.shared.v2.f32 	[%r566+4512], {%f1725, %f1726};
	st.shared.v2.f32 	[%r566+320], {%f1727, %f1728};
	st.shared.v2.f32 	[%r566+4544], {%f1729, %f1730};
	st.shared.v2.f32 	[%r566+352], {%f1731, %f1732};
	st.shared.v2.f32 	[%r566+4576], {%f1733, %f1734};
	st.shared.v2.f32 	[%r566+384], {%f1735, %f1736};
	st.shared.v2.f32 	[%r566+4608], {%f1737, %f1738};
	st.shared.v2.f32 	[%r566+416], {%f1739, %f1740};
	st.shared.v2.f32 	[%r566+4640], {%f1741, %f1742};
	st.shared.v2.f32 	[%r566+448], {%f1743, %f1744};
	st.shared.v2.f32 	[%r566+4672], {%f1745, %f1746};
	st.shared.v2.f32 	[%r566+480], {%f1747, %f1748};
	st.shared.v2.f32 	[%r566+4704], {%f1749, %f1750};
	bar.sync 	0;
	shl.b32 	%r567, %r523, 2;
	mad.lo.s32 	%r568, %r7, 132, %r567;
	shl.b32 	%r569, %r568, 2;
	add.s32 	%r570, %r141, %r569;
	ld.shared.v4.u32 	{%r363, %r364, %r365, %r366}, [%r570];
	ld.shared.v4.u32 	{%r367, %r368, %r369, %r370}, [%r570+2112];
	ld.shared.v4.u32 	{%r371, %r372, %r373, %r374}, [%r570+4224];
	ld.shared.v4.u32 	{%r375, %r376, %r377, %r378}, [%r570+6336];
	ld.shared.v4.u32 	{%r379, %r380, %r381, %r382}, [%r570+8448];
	ld.shared.v4.u32 	{%r383, %r384, %r385, %r386}, [%r570+10560];
	ld.shared.v4.u32 	{%r387, %r388, %r389, %r390}, [%r570+12672];
	ld.shared.v4.u32 	{%r391, %r392, %r393, %r394}, [%r570+14784];
	ld.shared.v4.u32 	{%r395, %r396, %r397, %r398}, [%r570+16896];
	ld.shared.v4.u32 	{%r399, %r400, %r401, %r402}, [%r570+19008];
	ld.shared.v4.u32 	{%r403, %r404, %r405, %r406}, [%r570+21120];
	ld.shared.v4.u32 	{%r407, %r408, %r409, %r410}, [%r570+23232];
	ld.shared.v4.u32 	{%r411, %r412, %r413, %r414}, [%r570+25344];
	ld.shared.v4.u32 	{%r415, %r416, %r417, %r418}, [%r570+27456];
	ld.shared.v4.u32 	{%r419, %r420, %r421, %r422}, [%r570+29568];
	ld.shared.v4.u32 	{%r423, %r424, %r425, %r426}, [%r570+31680];
	bar.sync 	0;
	st.shared.v2.f32 	[%r566], {%f1751, %f1752};
	st.shared.v2.f32 	[%r566+4224], {%f1753, %f1754};
	st.shared.v2.f32 	[%r566+32], {%f1755, %f1756};
	st.shared.v2.f32 	[%r566+4256], {%f1757, %f1758};
	st.shared.v2.f32 	[%r566+64], {%f1759, %f1760};
	st.shared.v2.f32 	[%r566+4288], {%f1761, %f1762};
	st.shared.v2.f32 	[%r566+96], {%f1763, %f1764};
	st.shared.v2.f32 	[%r566+4320], {%f1765, %f1766};
	st.shared.v2.f32 	[%r566+128], {%f1767, %f1768};
	st.shared.v2.f32 	[%r566+4352], {%f1769, %f1770};
	st.shared.v2.f32 	[%r566+160], {%f1771, %f1772};
	st.shared.v2.f32 	[%r566+4384], {%f1773, %f1774};
	st.shared.v2.f32 	[%r566+192], {%f1775, %f1776};
	st.shared.v2.f32 	[%r566+4416], {%f1777, %f1778};
	st.shared.v2.f32 	[%r566+224], {%f1779, %f1780};
	st.shared.v2.f32 	[%r566+4448], {%f1781, %f1782};
	st.shared.v2.f32 	[%r566+256], {%f1783, %f1784};
	st.shared.v2.f32 	[%r566+4480], {%f1785, %f1786};
	st.shared.v2.f32 	[%r566+288], {%f1787, %f1788};
	st.shared.v2.f32 	[%r566+4512], {%f1789, %f1790};
	st.shared.v2.f32 	[%r566+320], {%f1791, %f1792};
	st.shared.v2.f32 	[%r566+4544], {%f1793, %f1794};
	st.shared.v2.f32 	[%r566+352], {%f1795, %f1796};
	st.shared.v2.f32 	[%r566+4576], {%f1797, %f1798};
	st.shared.v2.f32 	[%r566+384], {%f1799, %f1800};
	st.shared.v2.f32 	[%r566+4608], {%f1801, %f1802};
	st.shared.v2.f32 	[%r566+416], {%f1803, %f1804};
	st.shared.v2.f32 	[%r566+4640], {%f1805, %f1806};
	st.shared.v2.f32 	[%r566+448], {%f1807, %f1808};
	st.shared.v2.f32 	[%r566+4672], {%f1809, %f1810};
	st.shared.v2.f32 	[%r566+480], {%f1811, %f1812};
	st.shared.v2.f32 	[%r566+4704], {%f1813, %f1814};
	bar.sync 	0;
	ld.shared.v4.u32 	{%r427, %r428, %r429, %r430}, [%r570];
	ld.shared.v4.u32 	{%r431, %r432, %r433, %r434}, [%r570+2112];
	ld.shared.v4.u32 	{%r435, %r436, %r437, %r438}, [%r570+4224];
	ld.shared.v4.u32 	{%r439, %r440, %r441, %r442}, [%r570+6336];
	ld.shared.v4.u32 	{%r443, %r444, %r445, %r446}, [%r570+8448];
	ld.shared.v4.u32 	{%r447, %r448, %r449, %r450}, [%r570+10560];
	ld.shared.v4.u32 	{%r451, %r452, %r453, %r454}, [%r570+12672];
	ld.shared.v4.u32 	{%r455, %r456, %r457, %r458}, [%r570+14784];
	ld.shared.v4.u32 	{%r459, %r460, %r461, %r462}, [%r570+16896];
	ld.shared.v4.u32 	{%r463, %r464, %r465, %r466}, [%r570+19008];
	ld.shared.v4.u32 	{%r467, %r468, %r469, %r470}, [%r570+21120];
	ld.shared.v4.u32 	{%r471, %r472, %r473, %r474}, [%r570+23232];
	ld.shared.v4.u32 	{%r475, %r476, %r477, %r478}, [%r570+25344];
	ld.shared.v4.u32 	{%r479, %r480, %r481, %r482}, [%r570+27456];
	ld.shared.v4.u32 	{%r483, %r484, %r485, %r486}, [%r570+29568];
	ld.shared.v4.u32 	{%r487, %r488, %r489, %r490}, [%r570+31680];
	// begin inline asm
	@%p106 st.global.v4.b32 [ %rd99 + 0 ], { %r363, %r364, %r365, %r366 };
	// end inline asm
	// begin inline asm
	@%p107 st.global.v4.b32 [ %rd100 + 0 ], { %r367, %r368, %r369, %r370 };
	// end inline asm
	// begin inline asm
	@%p108 st.global.v4.b32 [ %rd101 + 0 ], { %r371, %r372, %r373, %r374 };
	// end inline asm
	// begin inline asm
	@%p109 st.global.v4.b32 [ %rd102 + 0 ], { %r375, %r376, %r377, %r378 };
	// end inline asm
	// begin inline asm
	@%p110 st.global.v4.b32 [ %rd103 + 0 ], { %r379, %r380, %r381, %r382 };
	// end inline asm
	// begin inline asm
	@%p111 st.global.v4.b32 [ %rd104 + 0 ], { %r383, %r384, %r385, %r386 };
	// end inline asm
	// begin inline asm
	@%p112 st.global.v4.b32 [ %rd105 + 0 ], { %r387, %r388, %r389, %r390 };
	// end inline asm
	// begin inline asm
	@%p113 st.global.v4.b32 [ %rd106 + 0 ], { %r391, %r392, %r393, %r394 };
	// end inline asm
	// begin inline asm
	@%p114 st.global.v4.b32 [ %rd107 + 0 ], { %r395, %r396, %r397, %r398 };
	// end inline asm
	// begin inline asm
	@%p115 st.global.v4.b32 [ %rd108 + 0 ], { %r399, %r400, %r401, %r402 };
	// end inline asm
	// begin inline asm
	@%p116 st.global.v4.b32 [ %rd109 + 0 ], { %r403, %r404, %r405, %r406 };
	// end inline asm
	// begin inline asm
	@%p117 st.global.v4.b32 [ %rd110 + 0 ], { %r407, %r408, %r409, %r410 };
	// end inline asm
	// begin inline asm
	@%p118 st.global.v4.b32 [ %rd111 + 0 ], { %r411, %r412, %r413, %r414 };
	// end inline asm
	// begin inline asm
	@%p119 st.global.v4.b32 [ %rd112 + 0 ], { %r415, %r416, %r417, %r418 };
	// end inline asm
	// begin inline asm
	@%p120 st.global.v4.b32 [ %rd113 + 0 ], { %r419, %r420, %r421, %r422 };
	// end inline asm
	// begin inline asm
	@%p121 st.global.v4.b32 [ %rd114 + 0 ], { %r423, %r424, %r425, %r426 };
	// end inline asm
	// begin inline asm
	@%p122 st.global.v4.b32 [ %rd115 + 0 ], { %r427, %r428, %r429, %r430 };
	// end inline asm
	// begin inline asm
	@%p123 st.global.v4.b32 [ %rd116 + 0 ], { %r431, %r432, %r433, %r434 };
	// end inline asm
	// begin inline asm
	@%p124 st.global.v4.b32 [ %rd117 + 0 ], { %r435, %r436, %r437, %r438 };
	// end inline asm
	// begin inline asm
	@%p125 st.global.v4.b32 [ %rd118 + 0 ], { %r439, %r440, %r441, %r442 };
	// end inline asm
	// begin inline asm
	@%p126 st.global.v4.b32 [ %rd119 + 0 ], { %r443, %r444, %r445, %r446 };
	// end inline asm
	// begin inline asm
	@%p127 st.global.v4.b32 [ %rd120 + 0 ], { %r447, %r448, %r449, %r450 };
	// end inline asm
	// begin inline asm
	@%p128 st.global.v4.b32 [ %rd121 + 0 ], { %r451, %r452, %r453, %r454 };
	// end inline asm
	// begin inline asm
	@%p129 st.global.v4.b32 [ %rd122 + 0 ], { %r455, %r456, %r457, %r458 };
	// end inline asm
	// begin inline asm
	@%p130 st.global.v4.b32 [ %rd123 + 0 ], { %r459, %r460, %r461, %r462 };
	// end inline asm
	// begin inline asm
	@%p131 st.global.v4.b32 [ %rd124 + 0 ], { %r463, %r464, %r465, %r466 };
	// end inline asm
	// begin inline asm
	@%p132 st.global.v4.b32 [ %rd125 + 0 ], { %r467, %r468, %r469, %r470 };
	// end inline asm
	// begin inline asm
	@%p133 st.global.v4.b32 [ %rd126 + 0 ], { %r471, %r472, %r473, %r474 };
	// end inline asm
	// begin inline asm
	@%p134 st.global.v4.b32 [ %rd127 + 0 ], { %r475, %r476, %r477, %r478 };
	// end inline asm
	// begin inline asm
	@%p135 st.global.v4.b32 [ %rd128 + 0 ], { %r479, %r480, %r481, %r482 };
	// end inline asm
	// begin inline asm
	@%p136 st.global.v4.b32 [ %rd129 + 0 ], { %r483, %r484, %r485, %r486 };
	// end inline asm
	// begin inline asm
	@%p137 st.global.v4.b32 [ %rd130 + 0 ], { %r487, %r488, %r489, %r490 };
	// end inline asm
	.loc	1 67 4
	ret;
$L__tmp3:
$L__func_end0:

}
	.file	1 "/tmp/tmpxs4syaq4.py"
	.file	2 "/usr/local/lib/python3.10/site-packages/triton/language/standard.py"
	.section	.debug_abbrev
	{
.b8 1
.b8 17
.b8 1
.b8 37
.b8 8
.b8 19
.b8 5
.b8 3
.b8 8
.b8 16
.b8 6
.b8 27
.b8 8
.b8 17
.b8 1
.b8 18
.b8 1
.b8 0
.b8 0
.b8 2
.b8 46
.b8 0
.b8 3
.b8 8
.b8 32
.b8 11
.b8 0
.b8 0
.b8 3
.b8 46
.b8 1
.b8 17
.b8 1
.b8 18
.b8 1
.b8 49
.b8 19
.b8 0
.b8 0
.b8 4
.b8 29
.b8 0
.b8 49
.b8 19
.b8 17
.b8 1
.b8 18
.b8 1
.b8 88
.b8 11
.b8 89
.b8 11
.b8 87
.b8 11
.b8 0
.b8 0
.b8 0
	}
	.section	.debug_info
	{
.b32 120
.b8 2
.b8 0
.b32 .debug_abbrev
.b8 8
.b8 1
.b8 116
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2
.b8 0
.b8 116
.b8 109
.b8 112
.b8 120
.b8 115
.b8 52
.b8 115
.b8 121
.b8 97
.b8 113
.b8 52
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line
.b8 47
.b8 116
.b8 109
.b8 112
.b8 0
.b64 $L__func_begin0
.b64 $L__func_end0
.b8 2
.b8 109
.b8 97
.b8 116
.b8 109
.b8 117
.b8 108
.b8 95
.b8 107
.b8 101
.b8 114
.b8 110
.b8 101
.b8 108
.b8 0
.b8 1
.b8 3
.b64 $L__func_begin0
.b64 $L__func_end0
.b32 61
.b8 4
.b32 61
.b64 $L__tmp1
.b64 $L__tmp2
.b8 1
.b8 24
.b8 27
.b8 0
.b8 0
	}
	.section	.debug_loc	{	}
