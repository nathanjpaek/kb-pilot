import torch
import torch.nn.functional as F
from torch import nn


class CPNLoss(nn.Module):
    """This is the loss function used for Cascaded Pyramid Net. Note that the
    original paper (arXiv:1711.07319) uses L2 loss. However the author (Shiyu)
    who participated in the FashionAI Keypoints competition found that L1 loss
    gave him a better result.

    Note that loss function is not used in test time. We simply want the
    predicted heatmaps generated by CPN.
    """

    def __init__(self):
        super(CPNLoss, self).__init__()

    def l1_weighted_loss(self, hm_targets, hm_preds, vis_masks, ohkm=1.0):
        """
        Args:
            hm_targets (torch.tensor): [batch_size, num_keypoints, h, w]
                Ground-truth heatmaps
            hm_preds (torch.tensor): [batch_size, num_keypoints, h, w]
                Predicted heatmaps
            vis_masks (torch.tensor): [batch_size, num_keypoints]
                Masks that indicate whether keypoints exist for each image.
            ohkm (float):
                Stands for 'Online Hard Keypoints Mining (OHKM)'. Closely
                related to 'Online Hard Example Mining (OHEM)'. Read:
                http://www.erogol.com/online-hard-example-mining-pytorch/

        Returns:
            float: A weighted loss between easy examples and hard examples.
        """
        hm_preds = F.relu(hm_preds, inplace=False)
        bs, num_kpts, h, w = hm_targets.size()
        hm_targets = hm_targets.view(bs, num_kpts, -1)
        hm_preds = hm_preds.view(bs, num_kpts, -1)
        vis_masks = vis_masks.view(bs, num_kpts, 1).repeat(1, 1, h * w)
        amplitude = torch.max(hm_targets)
        threshold = amplitude / 10
        easy_ids = ((hm_targets > threshold) & (vis_masks >= 0)).float()
        hard_ids = ((hm_targets <= threshold) & (vis_masks >= 0)).float()
        diff = (hm_targets - hm_preds).abs()
        epsilon = 0.0001
        easy_loss = (diff * easy_ids).sum(2).sum(0) / (easy_ids.sum(2).sum(
            0) + epsilon)
        hard_loss = (diff * hard_ids).sum(2).sum(0) / (hard_ids.sum(2).sum(
            0) + epsilon)
        total_loss = 0.5 * easy_loss + 0.5 * hard_loss
        if ohkm < 1:
            k = int(total_loss.size(0) * ohkm)
            total_loss, _ = total_loss.topk(k)
        return total_loss.mean()

    def forward(self, hm_targets, hm_global_preds, hm_refine_preds, vis_masks):
        """
        Args:
            hm_targets (torch.tensor): [batch_size, num_keypoints, h, w]
                Ground-truth heatmaps
            hm_global_preds (torch.tensor): [batch_size, num_keypoints, h, w]
                Predicted heatmaps (i.e. P2 layer) from GlobalNet.
            hm_refine_preds (torch.tensor): [batch_size, num_keypoints, h, w]
                Predicted heatmaps (i.e. concat output) from RefineNet.
            vis_masks (torch.tensor): [batch_size, num_keypoints]
                Masks that indicate whether keypoints exist for each image.
        Returns:
            float: Three different losses.
        """
        global_loss = self.l1_weighted_loss(hm_targets, hm_global_preds,
            vis_masks)
        refine_loss = self.l1_weighted_loss(hm_targets, hm_refine_preds,
            vis_masks, ohkm=0.5)
        return global_loss + refine_loss, global_loss, refine_loss


def get_inputs():
    return [torch.rand([4, 4, 4, 4]), torch.rand([4, 4, 4, 4]), torch.rand(
        [4, 4, 4, 4]), torch.rand([4, 4, 1])]


def get_init_inputs():
    return [[], {}]
