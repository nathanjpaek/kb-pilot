"""
Problem Name: 35_LTSM
Generated using DSPy RAG with openai/o3
RAG Examples: 8
Evaluation Result:
compiled=True correctness=True metadata={'hardware': 'NVIDIA H100 80GB HBM3', 'device': '0', 'correctness_trials': '(5 / 5)'} runtime=351.0 runtime_stats={'mean': 351.0, 'std': 8.38, 'min': 336.0, 'max': 373.0, 'num_trials': 100, 'performance_comparison': {'original_pytorch_stats': {'mean': 35.3, 'std': 1.4, 'min': 34.9, 'max': 45.5, 'num_trials': 100}, 'speedup_ratio': 0.101}}
"""

import math
import torch
import torch.nn as nn

import tilelang
import tilelang.language as T


# ----------------------------------------------------------------------
#  TileLang kernel builder :  (B*K) x (N, K)  -> (B, N)
# ----------------------------------------------------------------------
def build_linear_kernel(
    M: int,
    K: int,
    N: int,
    block_M: int = 128,
    block_N: int = 128,
    block_K: int = 32,
    dtype: str = "float16",
    accum_dtype: str = "float32",
):
    """
    Returns a TileLang kernel computing Y = X @ Wᵀ + B
        X : (M, K)
        W : (N, K)
        B : (N,)
        Y : (M, N)   (autogenerated)
    """

    @tilelang.jit(out_idx=-1)
    @T.prim_func
    def kernel(
        X: T.Tensor((M, K), dtype),
        W: T.Tensor((N, K), dtype),
        B: T.Tensor((N,), dtype),
        Y: T.Tensor((M, N), dtype),
    ):
        with T.Kernel(
            T.ceildiv(N, block_N),   # grid_x
            T.ceildiv(M, block_M),   # grid_y
            threads=128,
        ) as (bx, by):
            A_s = T.alloc_shared((block_M, block_K), dtype)
            B_s = T.alloc_shared((block_N, block_K), dtype)
            C_loc = T.alloc_fragment((block_M, block_N), accum_dtype)

            T.clear(C_loc)

            for ko in T.Pipelined(T.ceildiv(K, block_K), num_stages=2):
                # --- copy X tile -------------------------------------------------
                T.copy(
                    X[
                        by * block_M : (by + 1) * block_M,
                        ko * block_K : (ko + 1) * block_K,
                    ],
                    A_s,
                )
                # --- copy W tile -------------------------------------------------
                T.copy(
                    W[
                        bx * block_N : (bx + 1) * block_N,
                        ko * block_K : (ko + 1) * block_K,
                    ],
                    B_s,
                )
                # GEMM   (B_s already laid-out for transpose_B=True)
                T.gemm(A_s, B_s, C_loc, transpose_B=True)

            # -------- add bias & store ------------------------------------------
            for i, j in T.Parallel(block_M, block_N):
                g_m = by * block_M + i
                g_n = bx * block_N + j
                if (g_m < M) and (g_n < N):
                    val = C_loc[i, j] + B[g_n].astype(accum_dtype)
                    Y[g_m, g_n] = T.Cast(dtype, val)

    return kernel


# ----------------------------------------------------------------------
#                        ModelNew  (LSTM + FC)
# ----------------------------------------------------------------------
class LSTMLayer(nn.Module):
    """
    One uni-directional LSTM layer realised with TileLang GEMM kernels.
    """
    def __init__(self, input_size: int, hidden_size: int, bias: bool = True):
        super().__init__()
        gate_size = 4 * hidden_size

        # ---- parameters -------------------------------------------------------
        self.weight_ih = nn.Parameter(torch.empty(gate_size, input_size))
        self.weight_hh = nn.Parameter(torch.empty(gate_size, hidden_size))

        if bias:
            self.bias_ih = nn.Parameter(torch.empty(gate_size))
            self.bias_hh = nn.Parameter(torch.empty(gate_size))
        else:
            self.register_parameter("bias_ih", None)
            self.register_parameter("bias_hh", None)

        # identical to PyTorch initialisation
        stdv = 1.0 / math.sqrt(hidden_size)
        for p in self.parameters():
            if p is not None:
                p.data.uniform_(-stdv, stdv)

        # kernel cache
        self._kcache = {}

    # ---------------- helper ---------------------------------------------------
    def _get_kernel(self, M: int, K: int, N: int, dtype: str = "float16"):
        key = (M, K, N, dtype)
        if key not in self._kcache:
            self._kcache[key] = build_linear_kernel(M, K, N, dtype=dtype)
        return self._kcache[key]

    def _linear(self, X: torch.Tensor, W: torch.Tensor, B: torch.Tensor):
        """
        Thin wrapper around the TileLang GEMM kernel.
           X : (M,  K)
           W : (N,  K)   (NOT transposed)
           B : (N,)
        returns  (M, N)  float32
        """
        M, K = X.shape
        N = W.shape[0]
        ker = self._get_kernel(M, K, N, "float16")

        X_fp16 = X.to(dtype=torch.float16, device="cuda").contiguous()
        W_fp16 = W.to(dtype=torch.float16, device="cuda").contiguous()
        B_fp16 = B.to(dtype=torch.float16, device="cuda").contiguous()

        Y_fp16 = ker(X_fp16, W_fp16, B_fp16)
        return Y_fp16.to(torch.float32)

    # ---------------- forward --------------------------------------------------
    def forward(
        self,
        x_seq: torch.Tensor,        # (seq_len, batch, input_size)  float32
        h_prev: torch.Tensor,       # (batch, hidden)
        c_prev: torch.Tensor,       # (batch, hidden)
    ):
        seq_len, batch, _ = x_seq.shape
        hidden_size = h_prev.size(1)

        # -------- precompute input contribution for all timesteps --------------
        X2d = x_seq.reshape(seq_len * batch, -1)                      # (S*B, in)
        W_ih = self.weight_ih                                         # (4H, in)
        if self.bias_ih is None:
            b_ih = torch.zeros(
                4 * hidden_size, dtype=W_ih.dtype, device=W_ih.device
            )
        else:
            b_ih = self.bias_ih
        gates_x = self._linear(X2d, W_ih, b_ih).reshape(
            seq_len, batch, 4 * hidden_size
        )                                                             # (S, B, 4H)

        # ---- iterate timesteps -----------------------------------------------
        outputs = []
        h_t = h_prev
        c_t = c_prev
        for t in range(seq_len):
            # hidden contribution
            W_hh = self.weight_hh
            if self.bias_hh is None:
                b_hh = torch.zeros(
                    4 * hidden_size, dtype=W_hh.dtype, device=W_hh.device
                )
            else:
                b_hh = self.bias_hh
            gates_h = self._linear(h_t, W_hh, b_hh)                   # (B, 4H)

            gates = gates_x[t] + gates_h                              # (B, 4H)
            gi, gf, gc, go = gates.chunk(4, dim=1)

            i_gate = torch.sigmoid(gi)
            f_gate = torch.sigmoid(gf)
            g_gate = torch.tanh(gc)
            o_gate = torch.sigmoid(go)

            c_t = f_gate * c_t + i_gate * g_gate
            h_t = o_gate * torch.tanh(c_t)

            outputs.append(h_t)

        output_seq = torch.stack(outputs, dim=0)  # (seq_len, batch, hidden)
        return output_seq, h_t, c_t


class ModelNew(nn.Module):
    """
    LSTM → last-timestep FC   implemented with TileLang GEMM kernels.
    Shapes follow the original PyTorch model
        x : (B, Seq, In)
        out : (B, Out)
    """

    def __init__(
        self,
        input_size: int,
        hidden_size: int,
        num_layers: int,
        output_size: int,
        dropout: float = 0.0,
        bias: bool = True,
    ):
        super().__init__()
        self.num_layers = int(num_layers)
        self.hidden_size = int(hidden_size)

        # ----------- stacked LSTM layers ---------------------------------------
        layers = []
        for l in range(self.num_layers):
            in_size = input_size if l == 0 else hidden_size
            layers.append(LSTMLayer(in_size, hidden_size, bias=bias))
        self.layers = nn.ModuleList(layers)

        # ----------- final FC ---------------------------------------------------
        self.fc_weight = nn.Parameter(torch.empty(output_size, hidden_size))
        self.fc_bias = nn.Parameter(torch.empty(output_size))
        nn.init.kaiming_uniform_(self.fc_weight, a=math.sqrt(5))
        bound = 1.0 / math.sqrt(hidden_size)
        nn.init.uniform_(self.fc_bias, -bound, bound)

        #  initial states  (will be broadcast to runtime batch)
        self.register_buffer("h0", torch.randn(num_layers, 1, hidden_size))
        self.register_buffer("c0", torch.randn(num_layers, 1, hidden_size))

        # kernel cache for the final FC
        self._fc_cache = {}

    # ------------- helpers -----------------------------------------------------
    def _get_fc_kernel(self, M: int, dtype: str = "float16"):
        key = (M, dtype)
        if key not in self._fc_cache:
            self._fc_cache[key] = build_linear_kernel(
                M, self.hidden_size, self.fc_weight.size(0), dtype=dtype
            )
        return self._fc_cache[key]

    def _fc(self, X: torch.Tensor):
        """
        X : (B, hidden)  float32
        returns (B, out) float32
        """
        B = X.size(0)
        ker = self._get_fc_kernel(B, "float16")

        x_fp16 = X.to(dtype=torch.float16, device="cuda").contiguous()
        w_fp16 = self.fc_weight.to(dtype=torch.float16, device="cuda").contiguous()
        b_fp16 = self.fc_bias.to(dtype=torch.float16, device="cuda").contiguous()

        y_fp16 = ker(x_fp16, w_fp16, b_fp16)
        return y_fp16.to(torch.float32)

    # ------------- forward -----------------------------------------------------
    def forward(self, x: torch.Tensor):
        """
        x : (batch, seq_len, input_size)  (batch_first=True)
        returns (batch, output_size)
        """
        x = x.to(dtype=torch.float32, device="cuda").contiguous()
        batch, seq_len, _ = x.shape

        # initial states
        h_t = self.h0.repeat(1, batch, 1).to(dtype=torch.float32, device="cuda")
        c_t = self.c0.repeat(1, batch, 1).to(dtype=torch.float32, device="cuda")

        # ---- run stacked LSTM --------------------------------------------------
        layer_input = x.transpose(0, 1)          # (seq_len, batch, in)
        for layer_idx, layer in enumerate(self.layers):
            out_seq, h_t[layer_idx], c_t[layer_idx] = layer(
                layer_input, h_t[layer_idx], c_t[layer_idx]
            )
            layer_input = out_seq                # feed to next layer

        # ---- last timestep -----------------------------------------------------
        last_hidden = layer_input[-1]            # (batch, hidden)

        # ---- final FC ----------------------------------------------------------
        out = self._fc(last_hidden)
        return out